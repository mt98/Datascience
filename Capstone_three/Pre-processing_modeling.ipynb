{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this notebook we will be doing the pre-processing and modeling steps to build a model which would predict whether a patient has pneumonia or not using chest X-ray images. \n",
    "We will be using convolutional neural networks for predicting the patient status. Convolutional neural networks are commonly used for predictions in image based projects. They are used  due to their ability to extract local features,  with the use of kernels in the convolution layers  that are used to convolute the image to create feature maps. Along with convolutional layers there are pooling layers which extract the most important features and reduce the spatial dimensions.  \n",
    "We will be comparing two models, one of which is based on transfer learning, which is the Resnet50 model. Resnet50 stands for Residual Net and the model is a 50 layer deep model. In a residual network model, residual blocks are introduced in which in case layers are skipped if they reduce the performance of the network, which is a problem encountered with deep layer models. The model has been trained on ImageNet database.\n",
    "The other model with be a traditional CNN model that we have built.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let us import the libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import os\n",
    "import glob\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from sklearn.utils.class_weight import compute_class_weight\n",
    "from tensorflow.keras import datasets, layers, models\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Conv2D, MaxPool2D, Flatten, Dense, Dropout,BatchNormalization\n",
    "from tensorflow.keras.metrics import AUC, Precision, Recall, Accuracy\n",
    "import sklearn.utils\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.applications import ResNet50V2\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We have seen previously that the training dataset is class imbalanced. In order to help the data be generalized better and deal with class imbalance, we will be using a combination of data augmentation and balancing class weights in the model to deal with it."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let us load the training, testing and validation data. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_folder= '/Users/mks9338/Documents/Course/Capstone_three/chest_xray/train'\n",
    "testing_folder= '/Users/mks9338/Documents/Course/Capstone_three/chest_xray/test'\n",
    "validation_folder= '/Users/mks9338/Documents/Course/Capstone_three/chest_xray/val'\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will be using imagedata generator for the training and validation data, to creates modified images in real time while model is being trained. All the images will have normalized pixels by rescaling as part of imae processing. The test data set which we will be testing our fitted model on will have normalized pixels as part of the pre-processing "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_val_generator = ImageDataGenerator(rescale=1./255,horizontal_flip=True,zoom_range=0.3,rotation_range=5)\n",
    "test_generator = ImageDataGenerator(rescale=1./255)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using flow from directory function of image generator to take the files directly from the folder and also resizing the images to 224, 224. As data augmentation takes place, the images are chosen shuffled and the image remains three channel."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 5216 images belonging to 2 classes.\n"
     ]
    }
   ],
   "source": [
    "train = train_val_generator.flow_from_directory(training_folder, batch_size=64, target_size=(224,224), color_mode=\"rgb\",class_mode=\"binary\", shuffle=True, seed=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 16 images belonging to 2 classes.\n"
     ]
    }
   ],
   "source": [
    "val = train_val_generator.flow_from_directory(validation_folder,\n",
    "                                               batch_size=4,\n",
    "                                               target_size=(224,224),\n",
    "                                               color_mode=\"rgb\",\n",
    "                                               class_mode=\"binary\",\n",
    "                                               shuffle=True,\n",
    "                                               seed=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 624 images belonging to 2 classes.\n"
     ]
    }
   ],
   "source": [
    "test = test_generator.flow_from_directory(testing_folder,\n",
    "                                          batch_size=32,\n",
    "                                          target_size=(224,224),\n",
    "                                          color_mode=\"rgb\",\n",
    "                                          class_mode=\"binary\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will  be using the sklearn class weight function to allow balancing of the training dataset. The class weight function uses the inverse proportion of class frequency"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{0: 1.9448173005219984, 1: 0.6730322580645162}\n"
     ]
    }
   ],
   "source": [
    "\n",
    "class_weights = compute_class_weight(\n",
    "    'balanced',                  # Automatically balance the weights based on class frequency\n",
    "    classes=np.unique(train.classes),  # All unique class labels\n",
    "    y=train.classes         # All the labels in the dataset\n",
    ")\n",
    "\n",
    "# Convert the class weights to a dictionary format\n",
    "class_weight_dict = {i: class_weights[i] for i in range(len(class_weights))}\n",
    "\n",
    "print(class_weight_dict)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will use the transfer learning approach here using the resnet50 model with frozen weights chosen from the training on the imagenet dataset. The last dense layers will be removed and  we will be writing our own dense layers due to the binary classification required."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "resnet50 = ResNet50V2(weights = \"imagenet\", input_shape = (224,224,3), include_top = False)\n",
    "model = Sequential()\n",
    "\n",
    "model.add(resnet50)\n",
    "\n",
    "for layer in resnet50.layers:\n",
    "    layer.trainable = False\n",
    "    \n",
    "model.add(Flatten())\n",
    "\n",
    "model.add(Dense(units = 128, activation = \"relu\"))\n",
    "\n",
    "model.add(Dense(units = 1, activation = \"sigmoid\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " resnet50v2 (Functional)     (None, 7, 7, 2048)        23564800  \n",
      "                                                                 \n",
      " flatten_1 (Flatten)         (None, 100352)            0         \n",
      "                                                                 \n",
      " dense_2 (Dense)             (None, 128)               12845184  \n",
      "                                                                 \n",
      " dense_3 (Dense)             (None, 1)                 129       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 36,410,113\n",
      "Trainable params: 12,845,313\n",
      "Non-trainable params: 23,564,800\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "For optimization of weights, biases and learning rate we used the Adam optimizer, which is commonly used in image based cnn networks. Adam optimizer calculates changes based on using a combination of stochastic gradient descent and momentum.We used the binary cross entropy loss function, which is commonly used in classification neural network problems "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "82/82 [==============================] - 147s 2s/step - loss: 1.6287 - accuracy: 0.8978 - val_loss: 1.4359 - val_accuracy: 0.8750\n",
      "Epoch 2/10\n",
      "82/82 [==============================] - 146s 2s/step - loss: 0.4285 - accuracy: 0.9402 - val_loss: 0.8887 - val_accuracy: 0.7500\n",
      "Epoch 3/10\n",
      "82/82 [==============================] - 150s 2s/step - loss: 0.4751 - accuracy: 0.9335 - val_loss: 0.7171 - val_accuracy: 0.8750\n",
      "Epoch 4/10\n",
      "82/82 [==============================] - 162s 2s/step - loss: 0.3152 - accuracy: 0.9473 - val_loss: 1.3527 - val_accuracy: 0.8125\n",
      "Epoch 5/10\n",
      "82/82 [==============================] - 162s 2s/step - loss: 0.1483 - accuracy: 0.9617 - val_loss: 1.7583 - val_accuracy: 0.7500\n",
      "Epoch 6/10\n",
      "82/82 [==============================] - 164s 2s/step - loss: 0.1288 - accuracy: 0.9590 - val_loss: 0.2322 - val_accuracy: 0.9375\n",
      "Epoch 7/10\n",
      "82/82 [==============================] - 163s 2s/step - loss: 0.0921 - accuracy: 0.9664 - val_loss: 0.4124 - val_accuracy: 0.8750\n",
      "Epoch 8/10\n",
      "82/82 [==============================] - 161s 2s/step - loss: 0.1000 - accuracy: 0.9661 - val_loss: 0.6308 - val_accuracy: 0.8750\n",
      "Epoch 9/10\n",
      "82/82 [==============================] - 154s 2s/step - loss: 0.0910 - accuracy: 0.9705 - val_loss: 0.8225 - val_accuracy: 0.7500\n",
      "Epoch 10/10\n",
      "82/82 [==============================] - 158s 2s/step - loss: 0.0929 - accuracy: 0.9703 - val_loss: 0.7854 - val_accuracy: 0.8125\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x169071d90>"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.compile(optimizer = \"adam\", loss = \"binary_crossentropy\", metrics = [\"accuracy\"])\n",
    "model.fit(train,validation_data=val, epochs=10, class_weight=class_weight_dict)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The model does well on training and validation accuracy at 97% and 81.25% respectively"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will also test another model before deciding on using the Resnetv50 model for training. A CNN model was developed with three blocks with similar design. In the first block, we have  two convolution layers with kernel size of 3x3 with a total of 32 kernels. The activation function used in cnn is the non-linear RELU function, which returns the input value if it is positive and 0 otherwise. This helps it overcome the vanishing gradient problem with other functions during backpropogation. Batch normalization to prevent overfitting was carried out in between the two layers. We then followed it up with max-pooling to reduce the number of features wth the pol_size (2,2). \n",
    "This was followed by two more blocks with similar design except using 64 and 128 blocks\n",
    "\n",
    " The layers were then flattened and then the nodes from the second convolutional layer passed onto a  dense network with 128 neurons and the RELU activation function. The output was passed onto a single neuron which gave a probability score to classify an image as pneumonia or normal (1,0). Sigmoid function is used so that the output is a probability score."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "model1 = Sequential()\n",
    "\n",
    "model1.add(Conv2D(filters=32, kernel_size=(3, 3), input_shape=(224, 224, 3), activation='relu'))\n",
    "model1.add(BatchNormalization())\n",
    "model1.add(Conv2D(filters=32, kernel_size=(3, 3), input_shape=(224, 224, 3), activation='relu'))\n",
    "model1.add(BatchNormalization())\n",
    "model1.add(MaxPool2D(pool_size=(2, 2)))\n",
    "\n",
    "model1.add(Conv2D(filters=64, kernel_size=(3, 3), activation='relu'))\n",
    "model1.add(BatchNormalization())\n",
    "model1.add(Conv2D(filters=64, kernel_size=(3, 3), activation='relu'))\n",
    "model1.add(BatchNormalization())\n",
    "model1.add(MaxPool2D(pool_size=(2, 2)))\n",
    "\n",
    "model1.add(Conv2D(filters=128, kernel_size=(3, 3), activation='relu'))\n",
    "model1.add(BatchNormalization())\n",
    "model1.add(Conv2D(filters=128, kernel_size=(3, 3), activation='relu'))\n",
    "model1.add(BatchNormalization())\n",
    "model1.add(MaxPool2D(pool_size=(2, 2)))\n",
    "\n",
    "model1.add(Flatten())\n",
    "model1.add(Dense(128, activation='relu'))\n",
    "model1.add(Dense(1, activation='sigmoid'))\n",
    "\n",
    "model1.compile(loss='binary_crossentropy', \n",
    "              optimizer='adam', \n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-01-28 13:17:42.216511: W tensorflow/tsl/platform/profile_utils/cpu_utils.cc:128] Failed to get CPU frequency: 0 Hz\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "82/82 [==============================] - 307s 4s/step - loss: 2.7732 - accuracy: 0.8271 - val_loss: 10.3707 - val_accuracy: 0.5000\n",
      "Epoch 2/10\n",
      "82/82 [==============================] - 301s 4s/step - loss: 0.2451 - accuracy: 0.9080 - val_loss: 8.7351 - val_accuracy: 0.5000\n",
      "Epoch 3/10\n",
      "82/82 [==============================] - 303s 4s/step - loss: 0.1947 - accuracy: 0.9206 - val_loss: 11.5230 - val_accuracy: 0.5000\n",
      "Epoch 4/10\n",
      "82/82 [==============================] - 308s 4s/step - loss: 0.1793 - accuracy: 0.9306 - val_loss: 10.1595 - val_accuracy: 0.5000\n",
      "Epoch 5/10\n",
      "82/82 [==============================] - 315s 4s/step - loss: 0.2023 - accuracy: 0.9243 - val_loss: 18.4321 - val_accuracy: 0.5000\n",
      "Epoch 6/10\n",
      "82/82 [==============================] - 323s 4s/step - loss: 0.1663 - accuracy: 0.9354 - val_loss: 1.8769 - val_accuracy: 0.6875\n",
      "Epoch 7/10\n",
      "82/82 [==============================] - 309s 4s/step - loss: 0.1563 - accuracy: 0.9388 - val_loss: 1.0663 - val_accuracy: 0.5000\n",
      "Epoch 8/10\n",
      "82/82 [==============================] - 301s 4s/step - loss: 0.1505 - accuracy: 0.9417 - val_loss: 20.3698 - val_accuracy: 0.5000\n",
      "Epoch 9/10\n",
      "82/82 [==============================] - 341s 4s/step - loss: 0.1409 - accuracy: 0.9475 - val_loss: 8.7713 - val_accuracy: 0.5625\n",
      "Epoch 10/10\n",
      "82/82 [==============================] - 363s 4s/step - loss: 0.1443 - accuracy: 0.9421 - val_loss: 10.9155 - val_accuracy: 0.5625\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x1696dceb0>"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model1.fit(train,validation_data=val, epochs=10,class_weight=class_weight_dict)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The valication accuracy is very low with the CNN model. We will use the resnet model to evaluate the test dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20/20 [==============================] - 16s 806ms/step - loss: 0.2259 - accuracy: 0.9247\n",
      "Test Loss: 0.2258983999490738\n",
      "Test Accuracy: 0.9246794581413269\n"
     ]
    }
   ],
   "source": [
    "Test_loss, Test_accuracy = model.evaluate(test)\n",
    "print(f'Test Loss: {Test_loss}')\n",
    "print(f'Test Accuracy: {Test_accuracy}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With the resnet model we have acheived an accuracy of 92.5% on the test dataset"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tensor",
   "language": "python",
   "name": "tensor"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
