{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e268675c",
   "metadata": {},
   "source": [
    "# Modeling "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a861268a",
   "metadata": {},
   "source": [
    "In this notebook, we will be predicting the different UPDRS scores for the patients at each time point. We will be using the chosen protein and peptide abundances for the predictions. We will be using three different models light gbm, SVM and logistic regression and testing which one works best and gives the most optimal results. The reason that we chose light gbm rather than traditional gradient boosting models or random forest is its faster training time and higher accuracy. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b5b53ba",
   "metadata": {},
   "source": [
    "Load the libraries "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "75a0a4a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "import numpy as np\n",
    "from numpy import arange\n",
    "import pandas as pd\n",
    "import lightgbm\n",
    "from lightgbm import LGBMClassifier\n",
    "from bayes_opt import BayesianOptimization\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.model_selection import GridSearchCV, RepeatedKFold\n",
    "from sklearn.svm import SVC\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a5d22da8",
   "metadata": {},
   "source": [
    "Load the training and test datasets "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c3fb9314",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train=pd.read_csv(\"X_train.csv\",index_col=0)\n",
    "y_train=pd.read_csv('y_train.csv',index_col=0)\n",
    "X_test=pd.read_csv(\"X_test.csv\")\n",
    "y_test=pd.read_csv('y_test.csv')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d054b6e",
   "metadata": {},
   "source": [
    "Load the selected protein and peptide abundances which are important for each of the UPDRS scores based on the boruta algorithm."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1708f94a",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "features_UPDRS1=pd.read_csv(\"features_UPDRS1\",header=None)\n",
    "features_UPDRS2=pd.read_csv(\"features_UPDRS2\",header=None)\n",
    "features_UPDRS3=pd.read_csv(\"features_UPDRS3\",header=None)\n",
    "features_UPDRS4=pd.read_csv(\"features_UPDRS4\",header=None)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af86aacd",
   "metadata": {},
   "source": [
    "We will be modelling each of the developed UPDRS scores seperately with a light gbm model and doing hyper parameter tuning to get the parameters with the best cross validation. We will be using bayesian optimization for hyperparameter tuning when using lightgbm with five fold cross validation. Bayesian Optimization is performed over the specified search space (params_bounds) for a number of initial points (init_points) and iterations (n_iter).Apply the Bayesian optimizer to the function we created in the previous step to identify the best hyperparameters. We will run 10 iterations and set init_points = 2."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "91c28209",
   "metadata": {},
   "source": [
    "We will first be selecting the UPDRS 1 features only for X_train and then predicting the UPDRS 1 scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "59ff47ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_UPDRS1=X_train[features_UPDRS1.iloc[:,0].tolist()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "cecf6f52",
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = StandardScaler()\n",
    "X_tr_scaled_UPDRS1 = scaler.fit_transform(X_train_UPDRS1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10667b38",
   "metadata": {},
   "source": [
    "We will now be defining a function for five fold cross-validation with light gbm and apply it to each of the scores. The accuracy metric that we will be using is  RMSE (root mean square error), which measures the average difference between the values predicted by the model compared to the actual values. The RMSE score reported by scikit-learn's scoring mechanism is negative to ensure higher values still indicate better models. R2 values are another metric that can be used which is a scaled version of RMSE from 0 to 1. However, lightgbm regression did not have R2 as a metric so we used RMSE "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "67ecc872",
   "metadata": {},
   "outputs": [],
   "source": [
    "def lgb_bayes_optimize(X_train, y_train):\n",
    "    # Define the evaluation function for Bayesian Optimization\n",
    "    def lgb_eval(num_leaves, max_depth, lambda_l2, lambda_l1, min_child_samples, min_data_in_leaf):\n",
    "        params = {\"objective\" : \"regression\",\"metric\" : \"RMSE\",'is_unbalance': True,\"num_leaves\" : int(num_leaves), \"max_depth\" : int(max_depth),\n",
    " \"lambda_l2\" : lambda_l2,\"lambda_l1\" : lambda_l1,\"num_threads\" : 20, \"min_child_samples\" : int(min_child_samples), 'min_data_in_leaf': int(min_data_in_leaf),\n",
    "\"learning_rate\" : 0.03, \"subsample_freq\" : 5,\"verbosity\" : -1}\n",
    " # Create LightGBM datasets\n",
    "        lgtrain = lightgbm.Dataset(X_train, y_train)\n",
    "# Perform cross-validation with early stopping\n",
    "        cv_result = lightgbm.cv(params,\n",
    "                       lgtrain,\n",
    "                        num_boost_round=100,\n",
    "                       stratified=False, callbacks=[ lightgbm.early_stopping(stopping_rounds=1000),], nfold=3)\n",
    "        \n",
    "        # Return the negative RMSE to be maximized by Bayesian Optimization\n",
    "        return -1.0 * cv_result['valid rmse-mean'][-1]\n",
    "\n",
    "    # Define the search space for Bayesian Optimization\n",
    "    params_bounds = {\n",
    "        'num_leaves': (25, 4000),\n",
    "        'max_depth': (5, 63),\n",
    "        'lambda_l2': (0.0, 0.05),\n",
    "        'lambda_l1': (0.0, 0.05),\n",
    "        'min_child_samples': (50, 10000),\n",
    "        'min_data_in_leaf': (100, 2000)\n",
    "    }\n",
    "    \n",
    "    # Initialize Bayesian Optimization\n",
    "    lgbBO = BayesianOptimization(lgb_eval, params_bounds, random_state=42)\n",
    "\n",
    "    # Perform Bayesian Optimization\n",
    "    lgbBO.maximize(init_points=2, n_iter=10)\n",
    "\n",
    "    # Get the best parameters\n",
    "    best_params = lgbBO.max['params']\n",
    "    #Get rmse\n",
    "    rmse= lgbBO.max['target']\n",
    "       \n",
    "    return  best_params, rmse"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "218b6ecf",
   "metadata": {},
   "source": [
    "Train light gbm wth cross validation and hyperparameter tuning for UPDRS_1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c90dbdae",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "|   iter    |  target   | lambda_l1 | lambda_l2 | max_depth | min_ch... | min_da... | num_le... |\n",
      "-------------------------------------------------------------------------------------------------\n",
      "Training until validation scores don't improve for 1000 rounds\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[1]\tcv_agg's valid rmse: 5.32832 + 0.0533255\n",
      "| \u001b[0m1        \u001b[0m | \u001b[0m-5.328   \u001b[0m | \u001b[0m0.01873  \u001b[0m | \u001b[0m0.04754  \u001b[0m | \u001b[0m47.46    \u001b[0m | \u001b[0m6.007e+03\u001b[0m | \u001b[0m396.4    \u001b[0m | \u001b[0m645.1    \u001b[0m |\n",
      "Training until validation scores don't improve for 1000 rounds\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[100]\tcv_agg's valid rmse: 5.13183 + 0.0427376\n",
      "| \u001b[95m2        \u001b[0m | \u001b[95m-5.132   \u001b[0m | \u001b[95m0.002904 \u001b[0m | \u001b[95m0.04331  \u001b[0m | \u001b[95m39.86    \u001b[0m | \u001b[95m7.095e+03\u001b[0m | \u001b[95m139.1    \u001b[0m | \u001b[95m3.88e+03 \u001b[0m |\n",
      "Training until validation scores don't improve for 1000 rounds\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[1]\tcv_agg's valid rmse: 5.32832 + 0.0533255\n",
      "| \u001b[0m3        \u001b[0m | \u001b[0m-5.328   \u001b[0m | \u001b[0m0.03768  \u001b[0m | \u001b[0m0.04288  \u001b[0m | \u001b[0m39.23    \u001b[0m | \u001b[0m3.695e+03\u001b[0m | \u001b[0m937.8    \u001b[0m | \u001b[0m3.15e+03 \u001b[0m |\n",
      "Training until validation scores don't improve for 1000 rounds\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[1]\tcv_agg's valid rmse: 5.32832 + 0.0533255\n",
      "| \u001b[0m4        \u001b[0m | \u001b[0m-5.328   \u001b[0m | \u001b[0m0.00621  \u001b[0m | \u001b[0m0.03564  \u001b[0m | \u001b[0m47.96    \u001b[0m | \u001b[0m1.606e+03\u001b[0m | \u001b[0m1.304e+03\u001b[0m | \u001b[0m3.542e+03\u001b[0m |\n",
      "Training until validation scores don't improve for 1000 rounds\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[95]\tcv_agg's valid rmse: 5.1271 + 0.040013\n",
      "| \u001b[95m5        \u001b[0m | \u001b[95m-5.127   \u001b[0m | \u001b[95m0.03901  \u001b[0m | \u001b[95m0.0274   \u001b[0m | \u001b[95m7.125    \u001b[0m | \u001b[95m8.113e+03\u001b[0m | \u001b[95m196.8    \u001b[0m | \u001b[95m3.858e+03\u001b[0m |\n",
      "Training until validation scores don't improve for 1000 rounds\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[1]\tcv_agg's valid rmse: 5.32832 + 0.0533255\n",
      "| \u001b[0m6        \u001b[0m | \u001b[0m-5.328   \u001b[0m | \u001b[0m0.02847  \u001b[0m | \u001b[0m0.04289  \u001b[0m | \u001b[0m53.82    \u001b[0m | \u001b[0m9.905e+03\u001b[0m | \u001b[0m1.86e+03 \u001b[0m | \u001b[0m3.915e+03\u001b[0m |\n",
      "Training until validation scores don't improve for 1000 rounds\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[1]\tcv_agg's valid rmse: 5.32832 + 0.0533255\n",
      "| \u001b[0m7        \u001b[0m | \u001b[0m-5.328   \u001b[0m | \u001b[0m0.02189  \u001b[0m | \u001b[0m0.008072 \u001b[0m | \u001b[0m13.14    \u001b[0m | \u001b[0m65.09    \u001b[0m | \u001b[0m1.996e+03\u001b[0m | \u001b[0m2.143e+03\u001b[0m |\n",
      "Training until validation scores don't improve for 1000 rounds\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[1]\tcv_agg's valid rmse: 5.32832 + 0.0533255\n",
      "| \u001b[0m8        \u001b[0m | \u001b[0m-5.328   \u001b[0m | \u001b[0m0.001531 \u001b[0m | \u001b[0m0.02684  \u001b[0m | \u001b[0m58.63    \u001b[0m | \u001b[0m6.93e+03 \u001b[0m | \u001b[0m1.786e+03\u001b[0m | \u001b[0m3.986e+03\u001b[0m |\n",
      "Training until validation scores don't improve for 1000 rounds\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[100]\tcv_agg's valid rmse: 5.15811 + 0.0164824\n",
      "| \u001b[0m9        \u001b[0m | \u001b[0m-5.158   \u001b[0m | \u001b[0m0.02094  \u001b[0m | \u001b[0m0.03627  \u001b[0m | \u001b[0m35.22    \u001b[0m | \u001b[0m7.43e+03 \u001b[0m | \u001b[0m248.6    \u001b[0m | \u001b[0m155.0    \u001b[0m |\n",
      "Training until validation scores don't improve for 1000 rounds\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[83]\tcv_agg's valid rmse: 5.12288 + 0.0327421\n",
      "| \u001b[95m10       \u001b[0m | \u001b[95m-5.123   \u001b[0m | \u001b[95m0.01405  \u001b[0m | \u001b[95m0.01831  \u001b[0m | \u001b[95m26.27    \u001b[0m | \u001b[95m7.128e+03\u001b[0m | \u001b[95m121.7    \u001b[0m | \u001b[95m3.784e+03\u001b[0m |\n",
      "Training until validation scores don't improve for 1000 rounds\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[95]\tcv_agg's valid rmse: 5.12883 + 0.0333069\n",
      "| \u001b[0m11       \u001b[0m | \u001b[0m-5.129   \u001b[0m | \u001b[0m0.00114  \u001b[0m | \u001b[0m0.03117  \u001b[0m | \u001b[0m8.446    \u001b[0m | \u001b[0m7.98e+03 \u001b[0m | \u001b[0m159.2    \u001b[0m | \u001b[0m2.292e+03\u001b[0m |\n",
      "Training until validation scores don't improve for 1000 rounds\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[57]\tcv_agg's valid rmse: 5.1144 + 0.0256105\n",
      "| \u001b[95m12       \u001b[0m | \u001b[95m-5.114   \u001b[0m | \u001b[95m0.02158  \u001b[0m | \u001b[95m0.02651  \u001b[0m | \u001b[95m5.0      \u001b[0m | \u001b[95m9.404e+03\u001b[0m | \u001b[95m100.0    \u001b[0m | \u001b[95m25.0     \u001b[0m |\n",
      "=================================================================================================\n",
      "Best parameters found for UPDRS1: {'lambda_l1': 0.021577621783817603, 'lambda_l2': 0.02651382172389118, 'max_depth': 5.0, 'min_child_samples': 9403.696300031665, 'min_data_in_leaf': 100.0, 'num_leaves': 25.0}\n",
      "RMSE for UPDRS1 -5.1143988306518215\n"
     ]
    }
   ],
   "source": [
    "best_params, rmse = lgb_bayes_optimize(X_tr_scaled_UPDRS1,y_train.updrs_1)\n",
    "\n",
    "print(\"Best parameters found for UPDRS1:\", best_params)\n",
    "print(\"RMSE for UPDRS1\", rmse)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7117c25",
   "metadata": {},
   "source": [
    "We would like to see the best parameters and the mean RMSE for the training dataset prediction of UPDRS_1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a91f1ec1",
   "metadata": {},
   "source": [
    "After cross validation the RMSE  5.11. We can see if adding the minimum visit month difference and visit_month can improve the RMSE.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19426dbc",
   "metadata": {},
   "source": [
    "We have to convert the visit_month_difference NA which is for the visit month 0, which should be converted to 0 before using it as a feature\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "1a83e4b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train[\"visit_month_diff_min\"] = X_train[\"visit_month_diff_min\"].fillna(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "332b1506",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "|   iter    |  target   | lambda_l1 | lambda_l2 | max_depth | min_ch... | min_da... | num_le... |\n",
      "-------------------------------------------------------------------------------------------------\n",
      "Training until validation scores don't improve for 1000 rounds\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[1]\tcv_agg's valid rmse: 5.32832 + 0.0533255\n",
      "| \u001b[0m1        \u001b[0m | \u001b[0m-5.328   \u001b[0m | \u001b[0m0.01873  \u001b[0m | \u001b[0m0.04754  \u001b[0m | \u001b[0m47.46    \u001b[0m | \u001b[0m6.007e+03\u001b[0m | \u001b[0m396.4    \u001b[0m | \u001b[0m645.1    \u001b[0m |\n",
      "Training until validation scores don't improve for 1000 rounds\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[100]\tcv_agg's valid rmse: 4.92518 + 0.0778103\n",
      "| \u001b[95m2        \u001b[0m | \u001b[95m-4.925   \u001b[0m | \u001b[95m0.002904 \u001b[0m | \u001b[95m0.04331  \u001b[0m | \u001b[95m39.86    \u001b[0m | \u001b[95m7.095e+03\u001b[0m | \u001b[95m139.1    \u001b[0m | \u001b[95m3.88e+03 \u001b[0m |\n",
      "Training until validation scores don't improve for 1000 rounds\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[1]\tcv_agg's valid rmse: 5.32832 + 0.0533255\n",
      "| \u001b[0m3        \u001b[0m | \u001b[0m-5.328   \u001b[0m | \u001b[0m0.03768  \u001b[0m | \u001b[0m0.04288  \u001b[0m | \u001b[0m39.23    \u001b[0m | \u001b[0m3.695e+03\u001b[0m | \u001b[0m937.8    \u001b[0m | \u001b[0m3.15e+03 \u001b[0m |\n",
      "Training until validation scores don't improve for 1000 rounds\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[1]\tcv_agg's valid rmse: 5.32832 + 0.0533255\n",
      "| \u001b[0m4        \u001b[0m | \u001b[0m-5.328   \u001b[0m | \u001b[0m0.00621  \u001b[0m | \u001b[0m0.03564  \u001b[0m | \u001b[0m47.96    \u001b[0m | \u001b[0m1.606e+03\u001b[0m | \u001b[0m1.304e+03\u001b[0m | \u001b[0m3.542e+03\u001b[0m |\n",
      "Training until validation scores don't improve for 1000 rounds\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[99]\tcv_agg's valid rmse: 4.87975 + 0.0522143\n",
      "| \u001b[95m5        \u001b[0m | \u001b[95m-4.88    \u001b[0m | \u001b[95m0.03142  \u001b[0m | \u001b[95m0.003772 \u001b[0m | \u001b[95m13.07    \u001b[0m | \u001b[95m8.132e+03\u001b[0m | \u001b[95m100.6    \u001b[0m | \u001b[95m3.997e+03\u001b[0m |\n",
      "Training until validation scores don't improve for 1000 rounds\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[1]\tcv_agg's valid rmse: 5.32832 + 0.0533255\n",
      "| \u001b[0m6        \u001b[0m | \u001b[0m-5.328   \u001b[0m | \u001b[0m0.01624  \u001b[0m | \u001b[0m0.03727  \u001b[0m | \u001b[0m63.0     \u001b[0m | \u001b[0m1e+04    \u001b[0m | \u001b[0m2e+03    \u001b[0m | \u001b[0m4e+03    \u001b[0m |\n",
      "Training until validation scores don't improve for 1000 rounds\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[1]\tcv_agg's valid rmse: 5.32832 + 0.0533255\n",
      "| \u001b[0m7        \u001b[0m | \u001b[0m-5.328   \u001b[0m | \u001b[0m0.02189  \u001b[0m | \u001b[0m0.008072 \u001b[0m | \u001b[0m13.14    \u001b[0m | \u001b[0m65.09    \u001b[0m | \u001b[0m1.996e+03\u001b[0m | \u001b[0m2.143e+03\u001b[0m |\n",
      "Training until validation scores don't improve for 1000 rounds\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[99]\tcv_agg's valid rmse: 4.87975 + 0.052205\n",
      "| \u001b[0m8        \u001b[0m | \u001b[0m-4.88    \u001b[0m | \u001b[0m0.01222  \u001b[0m | \u001b[0m0.03804  \u001b[0m | \u001b[0m5.0      \u001b[0m | \u001b[0m8.281e+03\u001b[0m | \u001b[0m100.0    \u001b[0m | \u001b[0m2.601e+03\u001b[0m |\n",
      "Training until validation scores don't improve for 1000 rounds\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[100]\tcv_agg's valid rmse: 5.11941 + 0.00723553\n",
      "| \u001b[0m9        \u001b[0m | \u001b[0m-5.119   \u001b[0m | \u001b[0m0.02094  \u001b[0m | \u001b[0m0.03627  \u001b[0m | \u001b[0m35.22    \u001b[0m | \u001b[0m7.43e+03 \u001b[0m | \u001b[0m248.6    \u001b[0m | \u001b[0m155.0    \u001b[0m |\n",
      "Training until validation scores don't improve for 1000 rounds\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[100]\tcv_agg's valid rmse: 4.86324 + 0.0599295\n",
      "| \u001b[95m10       \u001b[0m | \u001b[95m-4.863   \u001b[0m | \u001b[95m0.01405  \u001b[0m | \u001b[95m0.01831  \u001b[0m | \u001b[95m26.27    \u001b[0m | \u001b[95m7.128e+03\u001b[0m | \u001b[95m121.7    \u001b[0m | \u001b[95m3.784e+03\u001b[0m |\n",
      "Training until validation scores don't improve for 1000 rounds\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[98]\tcv_agg's valid rmse: 4.87825 + 0.0520642\n",
      "| \u001b[0m11       \u001b[0m | \u001b[0m-4.878   \u001b[0m | \u001b[0m0.05     \u001b[0m | \u001b[0m0.0      \u001b[0m | \u001b[0m5.0      \u001b[0m | \u001b[0m7.515e+03\u001b[0m | \u001b[0m100.0    \u001b[0m | \u001b[0m3.067e+03\u001b[0m |\n",
      "Training until validation scores don't improve for 1000 rounds\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[1]\tcv_agg's valid rmse: 5.32832 + 0.0533255\n",
      "| \u001b[0m12       \u001b[0m | \u001b[0m-5.328   \u001b[0m | \u001b[0m0.02792  \u001b[0m | \u001b[0m0.001602 \u001b[0m | \u001b[0m26.14    \u001b[0m | \u001b[0m8.036e+03\u001b[0m | \u001b[0m698.3    \u001b[0m | \u001b[0m3.389e+03\u001b[0m |\n",
      "=================================================================================================\n",
      "Best parameters found for UPDRS1: {'lambda_l1': 0.014054041040552134, 'lambda_l2': 0.018307674033779177, 'max_depth': 26.27463091598586, 'min_child_samples': 7127.5209284143175, 'min_data_in_leaf': 121.68326687883841, 'num_leaves': 3784.0776005157313}\n",
      "RMSE for UPDRS1 -4.863244009191125\n"
     ]
    }
   ],
   "source": [
    "X_train_UPDRS1=X_train[features_UPDRS1.iloc[:,0].tolist()+[\"visit_month_diff_min\",\"visit_month\"]]\n",
    "X_tr_scaled_UPDRS1 = scaler.fit_transform(X_train_UPDRS1)\n",
    "\n",
    "best_params, rmse = lgb_bayes_optimize(X_tr_scaled_UPDRS1,y_train.updrs_1)\n",
    "RMSE_lightgbm={\"UPDRS_1\": rmse}\n",
    "print(\"Best parameters found for UPDRS1:\", best_params)\n",
    "print(\"RMSE for UPDRS1\", rmse)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "499906c7",
   "metadata": {},
   "source": [
    " RMSE is improved now is 4.86 by adding the visit min difference and visit id. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69ad9cf1",
   "metadata": {},
   "source": [
    "Let me see if the same model with UPDRS associated boruta associated features along with adding visit min difference and visit id works well for cross validation for the other UPDRS scores."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "1df3dbc3",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_UPDRS2=X_train[features_UPDRS2.iloc[:,0].tolist()+[\"visit_month_diff_min\",\"visit_month\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "1c37d0fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_tr_scaled_UPDRS2 = scaler.fit_transform(X_train_UPDRS2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "bbc21b5c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "|   iter    |  target   | lambda_l1 | lambda_l2 | max_depth | min_ch... | min_da... | num_le... |\n",
      "-------------------------------------------------------------------------------------------------\n",
      "Training until validation scores don't improve for 1000 rounds\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[1]\tcv_agg's valid rmse: 5.92679 + 0.225728\n",
      "| \u001b[0m1        \u001b[0m | \u001b[0m-5.927   \u001b[0m | \u001b[0m0.01873  \u001b[0m | \u001b[0m0.04754  \u001b[0m | \u001b[0m47.46    \u001b[0m | \u001b[0m6.007e+03\u001b[0m | \u001b[0m396.4    \u001b[0m | \u001b[0m645.1    \u001b[0m |\n",
      "Training until validation scores don't improve for 1000 rounds\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[100]\tcv_agg's valid rmse: 5.04551 + 0.203827\n",
      "| \u001b[95m2        \u001b[0m | \u001b[95m-5.046   \u001b[0m | \u001b[95m0.002904 \u001b[0m | \u001b[95m0.04331  \u001b[0m | \u001b[95m39.86    \u001b[0m | \u001b[95m7.095e+03\u001b[0m | \u001b[95m139.1    \u001b[0m | \u001b[95m3.88e+03 \u001b[0m |\n",
      "Training until validation scores don't improve for 1000 rounds\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[1]\tcv_agg's valid rmse: 5.92679 + 0.225728\n",
      "| \u001b[0m3        \u001b[0m | \u001b[0m-5.927   \u001b[0m | \u001b[0m0.03768  \u001b[0m | \u001b[0m0.04288  \u001b[0m | \u001b[0m39.23    \u001b[0m | \u001b[0m3.695e+03\u001b[0m | \u001b[0m937.8    \u001b[0m | \u001b[0m3.15e+03 \u001b[0m |\n",
      "Training until validation scores don't improve for 1000 rounds\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[1]\tcv_agg's valid rmse: 5.92679 + 0.225728\n",
      "| \u001b[0m4        \u001b[0m | \u001b[0m-5.927   \u001b[0m | \u001b[0m0.00621  \u001b[0m | \u001b[0m0.03564  \u001b[0m | \u001b[0m47.96    \u001b[0m | \u001b[0m1.606e+03\u001b[0m | \u001b[0m1.304e+03\u001b[0m | \u001b[0m3.542e+03\u001b[0m |\n",
      "Training until validation scores don't improve for 1000 rounds\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[100]\tcv_agg's valid rmse: 4.91081 + 0.108796\n",
      "| \u001b[95m5        \u001b[0m | \u001b[95m-4.911   \u001b[0m | \u001b[95m0.03142  \u001b[0m | \u001b[95m0.003772 \u001b[0m | \u001b[95m15.53    \u001b[0m | \u001b[95m8.097e+03\u001b[0m | \u001b[95m102.4    \u001b[0m | \u001b[95m4e+03    \u001b[0m |\n",
      "Training until validation scores don't improve for 1000 rounds\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[1]\tcv_agg's valid rmse: 5.92679 + 0.225728\n",
      "| \u001b[0m6        \u001b[0m | \u001b[0m-5.927   \u001b[0m | \u001b[0m0.01624  \u001b[0m | \u001b[0m0.03727  \u001b[0m | \u001b[0m63.0     \u001b[0m | \u001b[0m1e+04    \u001b[0m | \u001b[0m2e+03    \u001b[0m | \u001b[0m4e+03    \u001b[0m |\n",
      "Training until validation scores don't improve for 1000 rounds\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[1]\tcv_agg's valid rmse: 5.92679 + 0.225728\n",
      "| \u001b[0m7        \u001b[0m | \u001b[0m-5.927   \u001b[0m | \u001b[0m0.02189  \u001b[0m | \u001b[0m0.008072 \u001b[0m | \u001b[0m13.14    \u001b[0m | \u001b[0m65.09    \u001b[0m | \u001b[0m1.996e+03\u001b[0m | \u001b[0m2.143e+03\u001b[0m |\n",
      "Training until validation scores don't improve for 1000 rounds\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[100]\tcv_agg's valid rmse: 4.905 + 0.107439\n",
      "| \u001b[95m8        \u001b[0m | \u001b[95m-4.905   \u001b[0m | \u001b[95m0.02536  \u001b[0m | \u001b[95m0.04599  \u001b[0m | \u001b[95m5.0      \u001b[0m | \u001b[95m8.342e+03\u001b[0m | \u001b[95m100.0    \u001b[0m | \u001b[95m2.603e+03\u001b[0m |\n",
      "Training until validation scores don't improve for 1000 rounds\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[100]\tcv_agg's valid rmse: 5.34923 + 0.185076\n",
      "| \u001b[0m9        \u001b[0m | \u001b[0m-5.349   \u001b[0m | \u001b[0m0.02094  \u001b[0m | \u001b[0m0.03627  \u001b[0m | \u001b[0m35.22    \u001b[0m | \u001b[0m7.43e+03 \u001b[0m | \u001b[0m248.6    \u001b[0m | \u001b[0m155.0    \u001b[0m |\n",
      "Training until validation scores don't improve for 1000 rounds\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[100]\tcv_agg's valid rmse: 4.93376 + 0.11734\n",
      "| \u001b[0m10       \u001b[0m | \u001b[0m-4.934   \u001b[0m | \u001b[0m0.01405  \u001b[0m | \u001b[0m0.01831  \u001b[0m | \u001b[0m26.27    \u001b[0m | \u001b[0m7.128e+03\u001b[0m | \u001b[0m121.7    \u001b[0m | \u001b[0m3.784e+03\u001b[0m |\n",
      "Training until validation scores don't improve for 1000 rounds\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[1]\tcv_agg's valid rmse: 5.92679 + 0.225728\n",
      "| \u001b[0m11       \u001b[0m | \u001b[0m-5.927   \u001b[0m | \u001b[0m0.05     \u001b[0m | \u001b[0m0.0      \u001b[0m | \u001b[0m5.0      \u001b[0m | \u001b[0m7.506e+03\u001b[0m | \u001b[0m647.7    \u001b[0m | \u001b[0m3.006e+03\u001b[0m |\n",
      "Training until validation scores don't improve for 1000 rounds\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[100]\tcv_agg's valid rmse: 4.9031 + 0.109583\n",
      "| \u001b[95m12       \u001b[0m | \u001b[95m-4.903   \u001b[0m | \u001b[95m0.02913  \u001b[0m | \u001b[95m0.0      \u001b[0m | \u001b[95m5.0      \u001b[0m | \u001b[95m7.634e+03\u001b[0m | \u001b[95m100.0    \u001b[0m | \u001b[95m3.806e+03\u001b[0m |\n",
      "=================================================================================================\n",
      "Best parameters found for UPDRS1: {'lambda_l1': 0.029128913747232203, 'lambda_l2': 0.0, 'max_depth': 5.0, 'min_child_samples': 7633.50565306499, 'min_data_in_leaf': 100.0, 'num_leaves': 3805.656837988707}\n",
      "RMSE for UPDRS1 -4.90309557004587\n"
     ]
    }
   ],
   "source": [
    "\n",
    "best_params2, rmse2 = lgb_bayes_optimize(X_tr_scaled_UPDRS2,y_train.updrs_2)\n",
    "\n",
    "print(\"Best parameters found for UPDRS1:\", best_params2)\n",
    "print(\"RMSE for UPDRS1\", rmse2)\n",
    "RMSE_lightgbm={\"UPDRS_2\": rmse2}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ef5eef6",
   "metadata": {},
   "source": [
    "The best RMSE for lightgbm is 4.90 for predicting UPDRS2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "91b48240",
   "metadata": {},
   "source": [
    "Let us see the performance of light gbm with UPDRS3. We will be using the upd23b_clinical_state_on_medication as a feature as well along with the important protein/peptide abundance scores and visit_month and minimum visit_difference. upd23b_clinical_state_on_medication  is supposed to effect the UPDRS3 scores according to the initially provided information.\n",
    "Since our previous notebooks showed that upd23b_clinical_state_on_medication had many missing values and this itself may have some significance, we can replace missing values with a value like “Unknown” or “Missing” using the fillna() method. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "1db41401",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train[\"upd23b_clinical_state_on_medication\"] = X_train.upd23b_clinical_state_on_medication.fillna(\"Unknown\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "6b173248",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_UPDRS3=X_train[features_UPDRS3.iloc[:,0].tolist()+[\"visit_month_diff_min\",\"visit_month\",\"upd23b_clinical_state_on_medication\"]]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30d2b507",
   "metadata": {},
   "source": [
    "We need to transform the UPDRS3 scores as we have both numerical and categorical variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "1281ac96",
   "metadata": {},
   "outputs": [],
   "source": [
    "numeric_columns = X_train_UPDRS3.select_dtypes(include=['int64', 'float64']).columns\n",
    "categorical_columns =X_train_UPDRS3.select_dtypes(include=['object', 'bool']).columns\n",
    "\n",
    "pipeline=ColumnTransformer([\n",
    "    ('num',StandardScaler(),numeric_columns),\n",
    "    ('cat',OneHotEncoder(),categorical_columns),\n",
    "])\n",
    "\n",
    "X_tr_scaled_UPDRS3=pipeline.fit_transform(X_train_UPDRS3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "a49f3a4d",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "|   iter    |  target   | lambda_l1 | lambda_l2 | max_depth | min_ch... | min_da... | num_le... |\n",
      "-------------------------------------------------------------------------------------------------\n",
      "Training until validation scores don't improve for 1000 rounds\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[1]\tcv_agg's valid rmse: 14.9414 + 0.321264\n",
      "| \u001b[0m1        \u001b[0m | \u001b[0m-14.94   \u001b[0m | \u001b[0m0.01873  \u001b[0m | \u001b[0m0.04754  \u001b[0m | \u001b[0m47.46    \u001b[0m | \u001b[0m6.007e+03\u001b[0m | \u001b[0m396.4    \u001b[0m | \u001b[0m645.1    \u001b[0m |\n",
      "Training until validation scores don't improve for 1000 rounds\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[100]\tcv_agg's valid rmse: 10.1492 + 0.490032\n",
      "| \u001b[95m2        \u001b[0m | \u001b[95m-10.15   \u001b[0m | \u001b[95m0.002904 \u001b[0m | \u001b[95m0.04331  \u001b[0m | \u001b[95m39.86    \u001b[0m | \u001b[95m7.095e+03\u001b[0m | \u001b[95m139.1    \u001b[0m | \u001b[95m3.88e+03 \u001b[0m |\n",
      "Training until validation scores don't improve for 1000 rounds\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[1]\tcv_agg's valid rmse: 14.9414 + 0.321264\n",
      "| \u001b[0m3        \u001b[0m | \u001b[0m-14.94   \u001b[0m | \u001b[0m0.03768  \u001b[0m | \u001b[0m0.04288  \u001b[0m | \u001b[0m39.23    \u001b[0m | \u001b[0m3.695e+03\u001b[0m | \u001b[0m937.8    \u001b[0m | \u001b[0m3.15e+03 \u001b[0m |\n",
      "Training until validation scores don't improve for 1000 rounds\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[1]\tcv_agg's valid rmse: 14.9414 + 0.321264\n",
      "| \u001b[0m4        \u001b[0m | \u001b[0m-14.94   \u001b[0m | \u001b[0m0.00621  \u001b[0m | \u001b[0m0.03564  \u001b[0m | \u001b[0m47.96    \u001b[0m | \u001b[0m1.606e+03\u001b[0m | \u001b[0m1.304e+03\u001b[0m | \u001b[0m3.542e+03\u001b[0m |\n",
      "Training until validation scores don't improve for 1000 rounds\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[100]\tcv_agg's valid rmse: 10.0042 + 0.494952\n",
      "| \u001b[95m5        \u001b[0m | \u001b[95m-10.0    \u001b[0m | \u001b[95m0.0      \u001b[0m | \u001b[95m0.05     \u001b[0m | \u001b[95m15.36    \u001b[0m | \u001b[95m8.108e+03\u001b[0m | \u001b[95m100.0    \u001b[0m | \u001b[95m4e+03    \u001b[0m |\n",
      "Training until validation scores don't improve for 1000 rounds\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[1]\tcv_agg's valid rmse: 14.9414 + 0.321264\n",
      "| \u001b[0m6        \u001b[0m | \u001b[0m-14.94   \u001b[0m | \u001b[0m0.05     \u001b[0m | \u001b[0m0.03392  \u001b[0m | \u001b[0m63.0     \u001b[0m | \u001b[0m1e+04    \u001b[0m | \u001b[0m2e+03    \u001b[0m | \u001b[0m4e+03    \u001b[0m |\n",
      "Training until validation scores don't improve for 1000 rounds\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[1]\tcv_agg's valid rmse: 14.9414 + 0.321264\n",
      "| \u001b[0m7        \u001b[0m | \u001b[0m-14.94   \u001b[0m | \u001b[0m0.02189  \u001b[0m | \u001b[0m0.008072 \u001b[0m | \u001b[0m13.14    \u001b[0m | \u001b[0m65.09    \u001b[0m | \u001b[0m1.996e+03\u001b[0m | \u001b[0m2.143e+03\u001b[0m |\n",
      "Training until validation scores don't improve for 1000 rounds\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[100]\tcv_agg's valid rmse: 10.0042 + 0.49495\n",
      "| \u001b[0m8        \u001b[0m | \u001b[0m-10.0    \u001b[0m | \u001b[0m0.05     \u001b[0m | \u001b[0m0.05     \u001b[0m | \u001b[0m5.0      \u001b[0m | \u001b[0m8.231e+03\u001b[0m | \u001b[0m100.0    \u001b[0m | \u001b[0m2.536e+03\u001b[0m |\n",
      "Training until validation scores don't improve for 1000 rounds\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[100]\tcv_agg's valid rmse: 11.3129 + 0.437747\n",
      "| \u001b[0m9        \u001b[0m | \u001b[0m-11.31   \u001b[0m | \u001b[0m0.02094  \u001b[0m | \u001b[0m0.03627  \u001b[0m | \u001b[0m35.22    \u001b[0m | \u001b[0m7.43e+03 \u001b[0m | \u001b[0m248.6    \u001b[0m | \u001b[0m155.0    \u001b[0m |\n",
      "Training until validation scores don't improve for 1000 rounds\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[100]\tcv_agg's valid rmse: 10.1291 + 0.516045\n",
      "| \u001b[0m10       \u001b[0m | \u001b[0m-10.13   \u001b[0m | \u001b[0m0.01405  \u001b[0m | \u001b[0m0.01831  \u001b[0m | \u001b[0m26.27    \u001b[0m | \u001b[0m7.128e+03\u001b[0m | \u001b[0m121.7    \u001b[0m | \u001b[0m3.784e+03\u001b[0m |\n",
      "Training until validation scores don't improve for 1000 rounds\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[100]\tcv_agg's valid rmse: 9.99997 + 0.487424\n",
      "| \u001b[95m11       \u001b[0m | \u001b[95m-10.0    \u001b[0m | \u001b[95m0.05     \u001b[0m | \u001b[95m0.0      \u001b[0m | \u001b[95m5.0      \u001b[0m | \u001b[95m1e+04    \u001b[0m | \u001b[95m100.0    \u001b[0m | \u001b[95m25.0     \u001b[0m |\n",
      "Training until validation scores don't improve for 1000 rounds\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[1]\tcv_agg's valid rmse: 14.9414 + 0.321264\n",
      "| \u001b[0m12       \u001b[0m | \u001b[0m-14.94   \u001b[0m | \u001b[0m0.0      \u001b[0m | \u001b[0m0.0      \u001b[0m | \u001b[0m63.0     \u001b[0m | \u001b[0m9.182e+03\u001b[0m | \u001b[0m2e+03    \u001b[0m | \u001b[0m25.0     \u001b[0m |\n",
      "=================================================================================================\n",
      "Best parameters found for UPDRS1: {'lambda_l1': 0.029128913747232203, 'lambda_l2': 0.0, 'max_depth': 5.0, 'min_child_samples': 7633.50565306499, 'min_data_in_leaf': 100.0, 'num_leaves': 3805.656837988707}\n",
      "RMSE for UPDRS3 -9.999972075310824\n"
     ]
    }
   ],
   "source": [
    "\n",
    "best_params3, rmse3 = lgb_bayes_optimize(X_tr_scaled_UPDRS3,y_train.updrs_3)\n",
    "\n",
    "print(\"Best parameters found for UPDRS1:\", best_params2)\n",
    "print(\"RMSE for UPDRS3\", rmse3)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fdf60de8",
   "metadata": {},
   "source": [
    "\n",
    " The best RMSE for UPDRS3 is 9.999"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "43dfa2cf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "|   iter    |  target   | lambda_l1 | lambda_l2 | max_depth | min_ch... | min_da... | num_le... |\n",
      "-------------------------------------------------------------------------------------------------\n",
      "Training until validation scores don't improve for 1000 rounds\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[1]\tcv_agg's valid rmse: 2.4313 + 0.216878\n",
      "| \u001b[0m1        \u001b[0m | \u001b[0m-2.431   \u001b[0m | \u001b[0m0.01873  \u001b[0m | \u001b[0m0.04754  \u001b[0m | \u001b[0m47.46    \u001b[0m | \u001b[0m6.007e+03\u001b[0m | \u001b[0m396.4    \u001b[0m | \u001b[0m645.1    \u001b[0m |\n",
      "Training until validation scores don't improve for 1000 rounds\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[100]\tcv_agg's valid rmse: 2.25034 + 0.164896\n",
      "| \u001b[95m2        \u001b[0m | \u001b[95m-2.25    \u001b[0m | \u001b[95m0.002904 \u001b[0m | \u001b[95m0.04331  \u001b[0m | \u001b[95m39.86    \u001b[0m | \u001b[95m7.095e+03\u001b[0m | \u001b[95m139.1    \u001b[0m | \u001b[95m3.88e+03 \u001b[0m |\n",
      "Training until validation scores don't improve for 1000 rounds\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[1]\tcv_agg's valid rmse: 2.4313 + 0.216878\n",
      "| \u001b[0m3        \u001b[0m | \u001b[0m-2.431   \u001b[0m | \u001b[0m0.03768  \u001b[0m | \u001b[0m0.04288  \u001b[0m | \u001b[0m39.23    \u001b[0m | \u001b[0m3.695e+03\u001b[0m | \u001b[0m937.8    \u001b[0m | \u001b[0m3.15e+03 \u001b[0m |\n",
      "Training until validation scores don't improve for 1000 rounds\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[1]\tcv_agg's valid rmse: 2.4313 + 0.216878\n",
      "| \u001b[0m4        \u001b[0m | \u001b[0m-2.431   \u001b[0m | \u001b[0m0.00621  \u001b[0m | \u001b[0m0.03564  \u001b[0m | \u001b[0m47.96    \u001b[0m | \u001b[0m1.606e+03\u001b[0m | \u001b[0m1.304e+03\u001b[0m | \u001b[0m3.542e+03\u001b[0m |\n",
      "Training until validation scores don't improve for 1000 rounds\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[100]\tcv_agg's valid rmse: 2.20708 + 0.178442\n",
      "| \u001b[95m5        \u001b[0m | \u001b[95m-2.207   \u001b[0m | \u001b[95m0.03142  \u001b[0m | \u001b[95m0.003772 \u001b[0m | \u001b[95m8.279    \u001b[0m | \u001b[95m8.119e+03\u001b[0m | \u001b[95m101.3    \u001b[0m | \u001b[95m4e+03    \u001b[0m |\n",
      "Training until validation scores don't improve for 1000 rounds\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[1]\tcv_agg's valid rmse: 2.4313 + 0.216878\n",
      "| \u001b[0m6        \u001b[0m | \u001b[0m-2.431   \u001b[0m | \u001b[0m0.01624  \u001b[0m | \u001b[0m0.03727  \u001b[0m | \u001b[0m63.0     \u001b[0m | \u001b[0m1e+04    \u001b[0m | \u001b[0m2e+03    \u001b[0m | \u001b[0m4e+03    \u001b[0m |\n",
      "Training until validation scores don't improve for 1000 rounds\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[1]\tcv_agg's valid rmse: 2.4313 + 0.216878\n",
      "| \u001b[0m7        \u001b[0m | \u001b[0m-2.431   \u001b[0m | \u001b[0m0.02189  \u001b[0m | \u001b[0m0.008072 \u001b[0m | \u001b[0m13.14    \u001b[0m | \u001b[0m65.09    \u001b[0m | \u001b[0m1.996e+03\u001b[0m | \u001b[0m2.143e+03\u001b[0m |\n",
      "Training until validation scores don't improve for 1000 rounds\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[100]\tcv_agg's valid rmse: 2.25173 + 0.166399\n",
      "| \u001b[0m8        \u001b[0m | \u001b[0m-2.252   \u001b[0m | \u001b[0m0.003594 \u001b[0m | \u001b[0m0.01206  \u001b[0m | \u001b[0m13.38    \u001b[0m | \u001b[0m8.273e+03\u001b[0m | \u001b[0m141.9    \u001b[0m | \u001b[0m2.643e+03\u001b[0m |\n",
      "Training until validation scores don't improve for 1000 rounds\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[100]\tcv_agg's valid rmse: 2.35354 + 0.206495\n",
      "| \u001b[0m9        \u001b[0m | \u001b[0m-2.354   \u001b[0m | \u001b[0m0.02094  \u001b[0m | \u001b[0m0.03627  \u001b[0m | \u001b[0m35.22    \u001b[0m | \u001b[0m7.43e+03 \u001b[0m | \u001b[0m248.6    \u001b[0m | \u001b[0m155.0    \u001b[0m |\n",
      "Training until validation scores don't improve for 1000 rounds\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[100]\tcv_agg's valid rmse: 2.21506 + 0.172392\n",
      "| \u001b[0m10       \u001b[0m | \u001b[0m-2.215   \u001b[0m | \u001b[0m0.01405  \u001b[0m | \u001b[0m0.01831  \u001b[0m | \u001b[0m26.27    \u001b[0m | \u001b[0m7.128e+03\u001b[0m | \u001b[0m121.7    \u001b[0m | \u001b[0m3.784e+03\u001b[0m |\n",
      "Training until validation scores don't improve for 1000 rounds\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[100]\tcv_agg's valid rmse: 2.31843 + 0.185273\n",
      "| \u001b[0m11       \u001b[0m | \u001b[0m-2.318   \u001b[0m | \u001b[0m0.002119 \u001b[0m | \u001b[0m0.01014  \u001b[0m | \u001b[0m10.65    \u001b[0m | \u001b[0m7.738e+03\u001b[0m | \u001b[0m160.8    \u001b[0m | \u001b[0m3.487e+03\u001b[0m |\n",
      "Training until validation scores don't improve for 1000 rounds\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[100]\tcv_agg's valid rmse: 2.25032 + 0.165294\n",
      "| \u001b[0m12       \u001b[0m | \u001b[0m-2.25    \u001b[0m | \u001b[0m0.04103  \u001b[0m | \u001b[0m0.0004939\u001b[0m | \u001b[0m38.28    \u001b[0m | \u001b[0m6.942e+03\u001b[0m | \u001b[0m134.7    \u001b[0m | \u001b[0m3.436e+03\u001b[0m |\n",
      "=================================================================================================\n",
      "Best parameters found for UPDRS4: {'lambda_l1': 0.03142226382966506, 'lambda_l2': 0.003772365525456778, 'max_depth': 8.278846626745294, 'min_child_samples': 8119.452361397542, 'min_data_in_leaf': 101.28651698669455, 'num_leaves': 3999.918172611531}\n",
      "RMSE for UPDRS4 -2.2070769267466606\n"
     ]
    }
   ],
   "source": [
    "X_train_UPDRS4=X_train[features_UPDRS4.iloc[:,0].tolist()+[\"visit_month_diff_min\",\"visit_month\"]]\n",
    "\n",
    "X_tr_scaled_UPDRS4 = scaler.fit_transform(X_train_UPDRS4)\n",
    "\n",
    "\n",
    "best_params4, rmse4 = lgb_bayes_optimize(X_tr_scaled_UPDRS4,y_train.updrs_4)\n",
    "\n",
    "print(\"Best parameters found for UPDRS4:\", best_params4)\n",
    "print(\"RMSE for UPDRS4\", rmse4)\n",
    "RMSE_lightgbm={\"UPDRS_4\": rmse4}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a8c02250",
   "metadata": {},
   "source": [
    " The best RMSE for UPDRS4 is 2.20"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "08dc420f",
   "metadata": {},
   "source": [
    "The RMSE values are very high and show that the target variables are not being predicted by the selected features. In general the RMSE should be within 10% of the mean. When we look at the RMSE we can see that our RMSE are very high meaning that the features show little trend in predicting the UPDRS scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "3add3654",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'UPDRS1': 6.5664794007490634, 'UPDRS2': 5.821161048689139, 'UPDRS3': 17.316479400749063, 'UPDRS4': 1.0168539325842696}\n",
      "{'UPDRS_1': -4.863244009191125, 'UPDRS_2': -4.90309557004587, 'UPDRS_3': -9.999972075310824, 'UPDRS_4': -2.2070769267466606}\n"
     ]
    }
   ],
   "source": [
    "Mean_UPDRSscores={\"UPDRS1\":y_train.updrs_1.mean(),\"UPDRS2\":y_train.updrs_2.mean(),\"UPDRS3\":y_train.updrs_3.mean(),\"UPDRS4\":y_train.updrs_4.mean()}\n",
    "RMSE_lightgbm={\"UPDRS_1\": rmse,\"UPDRS_2\": rmse2,\"UPDRS_3\": rmse3,\"UPDRS_4\": rmse4}\n",
    "print(Mean_UPDRSscores)\n",
    "print(RMSE_lightgbm)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4322934b",
   "metadata": {},
   "source": [
    "Let me see how elastic net regression performs in cross validation in RMSE using the same features that we used for prediction for each of the UPDRS scores. We will be doing five fold cross validation using grid search for hyper parameter tuning looking at different kernels and regularization parameter C. We can do an exhaustive search using grid search looking at all possible combinations rather than a smart bayesian based approach as we have fewer parameters to tune."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "158b5b88",
   "metadata": {},
   "outputs": [],
   "source": [
    "def pred(x,y):\n",
    "    param_grid = {'C': [0.1, 1, 10], 'kernel': ['linear', 'rbf', 'poly']}\n",
    "    grid = GridSearchCV(SVC(), param_grid, refit = True, verbose = 3,scoring=\"neg_root_mean_squared_error\") \n",
    "  # fitting the models for grid search \n",
    "    grid.fit(x, y) \n",
    "    best_params = grid.best_params_\n",
    "    best_score = grid.best_score_\n",
    "    return(best_params,best_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "5ca44129",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 9 candidates, totalling 45 fits\n",
      "[CV 1/5] END .............C=0.1, kernel=linear;, score=-6.610 total time=   0.1s\n",
      "[CV 2/5] END .............C=0.1, kernel=linear;, score=-6.072 total time=   0.0s\n",
      "[CV 3/5] END .............C=0.1, kernel=linear;, score=-6.635 total time=   0.0s\n",
      "[CV 4/5] END .............C=0.1, kernel=linear;, score=-6.508 total time=   0.0s\n",
      "[CV 5/5] END .............C=0.1, kernel=linear;, score=-5.963 total time=   0.0s\n",
      "[CV 1/5] END ................C=0.1, kernel=rbf;, score=-7.741 total time=   0.1s\n",
      "[CV 2/5] END ................C=0.1, kernel=rbf;, score=-7.751 total time=   0.1s\n",
      "[CV 3/5] END ................C=0.1, kernel=rbf;, score=-7.929 total time=   0.1s\n",
      "[CV 4/5] END ................C=0.1, kernel=rbf;, score=-7.560 total time=   0.1s\n",
      "[CV 5/5] END ................C=0.1, kernel=rbf;, score=-7.540 total time=   0.1s\n",
      "[CV 1/5] END ...............C=0.1, kernel=poly;, score=-7.296 total time=   0.0s\n",
      "[CV 2/5] END ...............C=0.1, kernel=poly;, score=-7.448 total time=   0.0s\n",
      "[CV 3/5] END ...............C=0.1, kernel=poly;, score=-7.556 total time=   0.0s\n",
      "[CV 4/5] END ...............C=0.1, kernel=poly;, score=-7.341 total time=   0.0s\n",
      "[CV 5/5] END ...............C=0.1, kernel=poly;, score=-7.193 total time=   0.0s\n",
      "[CV 1/5] END ...............C=1, kernel=linear;, score=-6.095 total time=   0.1s\n",
      "[CV 2/5] END ...............C=1, kernel=linear;, score=-6.153 total time=   0.1s\n",
      "[CV 3/5] END ...............C=1, kernel=linear;, score=-6.276 total time=   0.1s\n",
      "[CV 4/5] END ...............C=1, kernel=linear;, score=-6.097 total time=   0.1s\n",
      "[CV 5/5] END ...............C=1, kernel=linear;, score=-6.134 total time=   0.1s\n",
      "[CV 1/5] END ..................C=1, kernel=rbf;, score=-6.403 total time=   0.1s\n",
      "[CV 2/5] END ..................C=1, kernel=rbf;, score=-6.236 total time=   0.1s\n",
      "[CV 3/5] END ..................C=1, kernel=rbf;, score=-6.303 total time=   0.1s\n",
      "[CV 4/5] END ..................C=1, kernel=rbf;, score=-6.307 total time=   0.1s\n",
      "[CV 5/5] END ..................C=1, kernel=rbf;, score=-6.416 total time=   0.1s\n",
      "[CV 1/5] END .................C=1, kernel=poly;, score=-7.138 total time=   0.0s\n",
      "[CV 2/5] END .................C=1, kernel=poly;, score=-6.875 total time=   0.0s\n",
      "[CV 3/5] END .................C=1, kernel=poly;, score=-7.367 total time=   0.0s\n",
      "[CV 4/5] END .................C=1, kernel=poly;, score=-7.042 total time=   0.0s\n",
      "[CV 5/5] END .................C=1, kernel=poly;, score=-6.770 total time=   0.0s\n",
      "[CV 1/5] END ..............C=10, kernel=linear;, score=-6.005 total time=   0.3s\n",
      "[CV 2/5] END ..............C=10, kernel=linear;, score=-6.098 total time=   0.2s\n",
      "[CV 3/5] END ..............C=10, kernel=linear;, score=-6.609 total time=   0.3s\n",
      "[CV 4/5] END ..............C=10, kernel=linear;, score=-6.124 total time=   0.3s\n",
      "[CV 5/5] END ..............C=10, kernel=linear;, score=-5.800 total time=   0.3s\n",
      "[CV 1/5] END .................C=10, kernel=rbf;, score=-6.361 total time=   0.1s\n",
      "[CV 2/5] END .................C=10, kernel=rbf;, score=-5.923 total time=   0.1s\n",
      "[CV 3/5] END .................C=10, kernel=rbf;, score=-6.744 total time=   0.1s\n",
      "[CV 4/5] END .................C=10, kernel=rbf;, score=-5.941 total time=   0.1s\n",
      "[CV 5/5] END .................C=10, kernel=rbf;, score=-5.847 total time=   0.1s\n",
      "[CV 1/5] END ................C=10, kernel=poly;, score=-6.221 total time=   0.1s\n",
      "[CV 2/5] END ................C=10, kernel=poly;, score=-6.220 total time=   0.1s\n",
      "[CV 3/5] END ................C=10, kernel=poly;, score=-6.719 total time=   0.1s\n",
      "[CV 4/5] END ................C=10, kernel=poly;, score=-5.899 total time=   0.1s\n",
      "[CV 5/5] END ................C=10, kernel=poly;, score=-5.892 total time=   0.1s\n"
     ]
    }
   ],
   "source": [
    "SVM_updrs1=pred(X_tr_scaled_UPDRS1, y_train.updrs_1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "d8da1a7d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 9 candidates, totalling 45 fits\n",
      "[CV 1/5] END .............C=0.1, kernel=linear;, score=-6.657 total time=   0.1s\n",
      "[CV 2/5] END .............C=0.1, kernel=linear;, score=-6.594 total time=   0.0s\n",
      "[CV 3/5] END .............C=0.1, kernel=linear;, score=-6.570 total time=   0.0s\n",
      "[CV 4/5] END .............C=0.1, kernel=linear;, score=-5.945 total time=   0.0s\n",
      "[CV 5/5] END .............C=0.1, kernel=linear;, score=-6.342 total time=   0.0s\n",
      "[CV 1/5] END ................C=0.1, kernel=rbf;, score=-8.194 total time=   0.1s\n",
      "[CV 2/5] END ................C=0.1, kernel=rbf;, score=-8.314 total time=   0.1s\n",
      "[CV 3/5] END ................C=0.1, kernel=rbf;, score=-8.503 total time=   0.1s\n",
      "[CV 4/5] END ................C=0.1, kernel=rbf;, score=-8.356 total time=   0.1s\n",
      "[CV 5/5] END ................C=0.1, kernel=rbf;, score=-8.172 total time=   0.1s\n",
      "[CV 1/5] END ...............C=0.1, kernel=poly;, score=-8.088 total time=   0.1s\n",
      "[CV 2/5] END ...............C=0.1, kernel=poly;, score=-8.289 total time=   0.1s\n",
      "[CV 3/5] END ...............C=0.1, kernel=poly;, score=-8.260 total time=   0.1s\n",
      "[CV 4/5] END ...............C=0.1, kernel=poly;, score=-7.736 total time=   0.1s\n",
      "[CV 5/5] END ...............C=0.1, kernel=poly;, score=-8.108 total time=   0.1s\n",
      "[CV 1/5] END ...............C=1, kernel=linear;, score=-6.400 total time=   0.1s\n",
      "[CV 2/5] END ...............C=1, kernel=linear;, score=-6.683 total time=   0.1s\n",
      "[CV 3/5] END ...............C=1, kernel=linear;, score=-6.920 total time=   0.1s\n",
      "[CV 4/5] END ...............C=1, kernel=linear;, score=-5.723 total time=   0.1s\n",
      "[CV 5/5] END ...............C=1, kernel=linear;, score=-6.727 total time=   0.1s\n",
      "[CV 1/5] END ..................C=1, kernel=rbf;, score=-6.951 total time=   0.1s\n",
      "[CV 2/5] END ..................C=1, kernel=rbf;, score=-6.656 total time=   0.1s\n",
      "[CV 3/5] END ..................C=1, kernel=rbf;, score=-7.095 total time=   0.1s\n",
      "[CV 4/5] END ..................C=1, kernel=rbf;, score=-6.964 total time=   0.1s\n",
      "[CV 5/5] END ..................C=1, kernel=rbf;, score=-6.876 total time=   0.1s\n",
      "[CV 1/5] END .................C=1, kernel=poly;, score=-7.979 total time=   0.1s\n",
      "[CV 2/5] END .................C=1, kernel=poly;, score=-8.055 total time=   0.1s\n",
      "[CV 3/5] END .................C=1, kernel=poly;, score=-7.889 total time=   0.1s\n",
      "[CV 4/5] END .................C=1, kernel=poly;, score=-7.585 total time=   0.1s\n",
      "[CV 5/5] END .................C=1, kernel=poly;, score=-7.782 total time=   0.1s\n",
      "[CV 1/5] END ..............C=10, kernel=linear;, score=-7.005 total time=   0.5s\n",
      "[CV 2/5] END ..............C=10, kernel=linear;, score=-6.901 total time=   0.5s\n",
      "[CV 3/5] END ..............C=10, kernel=linear;, score=-7.060 total time=   0.5s\n",
      "[CV 4/5] END ..............C=10, kernel=linear;, score=-6.916 total time=   0.5s\n",
      "[CV 5/5] END ..............C=10, kernel=linear;, score=-6.479 total time=   0.4s\n",
      "[CV 1/5] END .................C=10, kernel=rbf;, score=-6.488 total time=   0.1s\n",
      "[CV 2/5] END .................C=10, kernel=rbf;, score=-6.384 total time=   0.1s\n",
      "[CV 3/5] END .................C=10, kernel=rbf;, score=-7.022 total time=   0.1s\n",
      "[CV 4/5] END .................C=10, kernel=rbf;, score=-6.110 total time=   0.1s\n",
      "[CV 5/5] END .................C=10, kernel=rbf;, score=-6.064 total time=   0.1s\n",
      "[CV 1/5] END ................C=10, kernel=poly;, score=-7.195 total time=   0.1s\n",
      "[CV 2/5] END ................C=10, kernel=poly;, score=-7.328 total time=   0.1s\n",
      "[CV 3/5] END ................C=10, kernel=poly;, score=-7.519 total time=   0.1s\n",
      "[CV 4/5] END ................C=10, kernel=poly;, score=-6.789 total time=   0.1s\n",
      "[CV 5/5] END ................C=10, kernel=poly;, score=-7.293 total time=   0.1s\n"
     ]
    }
   ],
   "source": [
    "SVM_updrs2=pred(X_tr_scaled_UPDRS2, y_train.updrs_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "9fb6e4cb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 9 candidates, totalling 45 fits\n",
      "[CV 1/5] END ............C=0.1, kernel=linear;, score=-13.557 total time=   0.1s\n",
      "[CV 2/5] END ............C=0.1, kernel=linear;, score=-14.120 total time=   0.1s\n",
      "[CV 3/5] END ............C=0.1, kernel=linear;, score=-14.274 total time=   0.1s\n",
      "[CV 4/5] END ............C=0.1, kernel=linear;, score=-12.144 total time=   0.1s\n",
      "[CV 5/5] END ............C=0.1, kernel=linear;, score=-14.439 total time=   0.1s\n",
      "[CV 1/5] END ...............C=0.1, kernel=rbf;, score=-22.653 total time=   0.1s\n",
      "[CV 2/5] END ...............C=0.1, kernel=rbf;, score=-23.443 total time=   0.1s\n",
      "[CV 3/5] END ...............C=0.1, kernel=rbf;, score=-23.063 total time=   0.1s\n",
      "[CV 4/5] END ...............C=0.1, kernel=rbf;, score=-22.485 total time=   0.1s\n",
      "[CV 5/5] END ...............C=0.1, kernel=rbf;, score=-22.693 total time=   0.1s\n",
      "[CV 1/5] END ..............C=0.1, kernel=poly;, score=-22.284 total time=   0.1s\n",
      "[CV 2/5] END ..............C=0.1, kernel=poly;, score=-23.116 total time=   0.1s\n",
      "[CV 3/5] END ..............C=0.1, kernel=poly;, score=-21.834 total time=   0.1s\n",
      "[CV 4/5] END ..............C=0.1, kernel=poly;, score=-22.119 total time=   0.1s\n",
      "[CV 5/5] END ..............C=0.1, kernel=poly;, score=-22.665 total time=   0.1s\n",
      "[CV 1/5] END ..............C=1, kernel=linear;, score=-15.313 total time=   0.1s\n",
      "[CV 2/5] END ..............C=1, kernel=linear;, score=-13.325 total time=   0.1s\n",
      "[CV 3/5] END ..............C=1, kernel=linear;, score=-15.770 total time=   0.1s\n",
      "[CV 4/5] END ..............C=1, kernel=linear;, score=-12.689 total time=   0.1s\n",
      "[CV 5/5] END ..............C=1, kernel=linear;, score=-13.080 total time=   0.1s\n",
      "[CV 1/5] END .................C=1, kernel=rbf;, score=-18.685 total time=   0.1s\n",
      "[CV 2/5] END .................C=1, kernel=rbf;, score=-18.113 total time=   0.1s\n",
      "[CV 3/5] END .................C=1, kernel=rbf;, score=-18.080 total time=   0.1s\n",
      "[CV 4/5] END .................C=1, kernel=rbf;, score=-16.931 total time=   0.1s\n",
      "[CV 5/5] END .................C=1, kernel=rbf;, score=-18.733 total time=   0.1s\n",
      "[CV 1/5] END ................C=1, kernel=poly;, score=-21.721 total time=   0.1s\n",
      "[CV 2/5] END ................C=1, kernel=poly;, score=-22.548 total time=   0.1s\n",
      "[CV 3/5] END ................C=1, kernel=poly;, score=-21.592 total time=   0.1s\n",
      "[CV 4/5] END ................C=1, kernel=poly;, score=-21.163 total time=   0.1s\n",
      "[CV 5/5] END ................C=1, kernel=poly;, score=-21.889 total time=   0.1s\n",
      "[CV 1/5] END .............C=10, kernel=linear;, score=-15.367 total time=   0.3s\n",
      "[CV 2/5] END .............C=10, kernel=linear;, score=-13.873 total time=   0.3s\n",
      "[CV 3/5] END .............C=10, kernel=linear;, score=-17.191 total time=   0.2s\n",
      "[CV 4/5] END .............C=10, kernel=linear;, score=-13.710 total time=   0.3s\n",
      "[CV 5/5] END .............C=10, kernel=linear;, score=-15.048 total time=   0.3s\n",
      "[CV 1/5] END ................C=10, kernel=rbf;, score=-14.318 total time=   0.1s\n",
      "[CV 2/5] END ................C=10, kernel=rbf;, score=-13.566 total time=   0.1s\n",
      "[CV 3/5] END ................C=10, kernel=rbf;, score=-15.211 total time=   0.1s\n",
      "[CV 4/5] END ................C=10, kernel=rbf;, score=-12.851 total time=   0.1s\n",
      "[CV 5/5] END ................C=10, kernel=rbf;, score=-13.268 total time=   0.1s\n",
      "[CV 1/5] END ...............C=10, kernel=poly;, score=-17.640 total time=   0.1s\n",
      "[CV 2/5] END ...............C=10, kernel=poly;, score=-18.555 total time=   0.1s\n",
      "[CV 3/5] END ...............C=10, kernel=poly;, score=-19.288 total time=   0.1s\n",
      "[CV 4/5] END ...............C=10, kernel=poly;, score=-18.334 total time=   0.1s\n",
      "[CV 5/5] END ...............C=10, kernel=poly;, score=-19.200 total time=   0.1s\n"
     ]
    }
   ],
   "source": [
    "SVM_updrs3=pred(X_tr_scaled_UPDRS3, y_train.updrs_3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "4805dfa1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 9 candidates, totalling 45 fits\n",
      "[CV 1/5] END .............C=0.1, kernel=linear;, score=-2.676 total time=   0.0s\n",
      "[CV 2/5] END .............C=0.1, kernel=linear;, score=-2.880 total time=   0.0s\n",
      "[CV 3/5] END .............C=0.1, kernel=linear;, score=-2.630 total time=   0.0s\n",
      "[CV 4/5] END .............C=0.1, kernel=linear;, score=-2.441 total time=   0.0s\n",
      "[CV 5/5] END .............C=0.1, kernel=linear;, score=-2.560 total time=   0.0s\n",
      "[CV 1/5] END ................C=0.1, kernel=rbf;, score=-2.676 total time=   0.0s\n",
      "[CV 2/5] END ................C=0.1, kernel=rbf;, score=-2.880 total time=   0.0s\n",
      "[CV 3/5] END ................C=0.1, kernel=rbf;, score=-2.630 total time=   0.0s\n",
      "[CV 4/5] END ................C=0.1, kernel=rbf;, score=-2.441 total time=   0.0s\n",
      "[CV 5/5] END ................C=0.1, kernel=rbf;, score=-2.560 total time=   0.0s\n",
      "[CV 1/5] END ...............C=0.1, kernel=poly;, score=-2.676 total time=   0.0s\n",
      "[CV 2/5] END ...............C=0.1, kernel=poly;, score=-2.880 total time=   0.0s\n",
      "[CV 3/5] END ...............C=0.1, kernel=poly;, score=-2.630 total time=   0.0s\n",
      "[CV 4/5] END ...............C=0.1, kernel=poly;, score=-2.441 total time=   0.0s\n",
      "[CV 5/5] END ...............C=0.1, kernel=poly;, score=-2.560 total time=   0.0s\n",
      "[CV 1/5] END ...............C=1, kernel=linear;, score=-2.676 total time=   0.0s\n",
      "[CV 2/5] END ...............C=1, kernel=linear;, score=-2.880 total time=   0.0s\n",
      "[CV 3/5] END ...............C=1, kernel=linear;, score=-2.630 total time=   0.0s\n",
      "[CV 4/5] END ...............C=1, kernel=linear;, score=-2.441 total time=   0.0s\n",
      "[CV 5/5] END ...............C=1, kernel=linear;, score=-2.560 total time=   0.0s\n",
      "[CV 1/5] END ..................C=1, kernel=rbf;, score=-2.676 total time=   0.0s\n",
      "[CV 2/5] END ..................C=1, kernel=rbf;, score=-2.880 total time=   0.0s\n",
      "[CV 3/5] END ..................C=1, kernel=rbf;, score=-2.630 total time=   0.0s\n",
      "[CV 4/5] END ..................C=1, kernel=rbf;, score=-2.441 total time=   0.0s\n",
      "[CV 5/5] END ..................C=1, kernel=rbf;, score=-2.560 total time=   0.0s\n",
      "[CV 1/5] END .................C=1, kernel=poly;, score=-2.829 total time=   0.0s\n",
      "[CV 2/5] END .................C=1, kernel=poly;, score=-2.801 total time=   0.0s\n",
      "[CV 3/5] END .................C=1, kernel=poly;, score=-2.630 total time=   0.0s\n",
      "[CV 4/5] END .................C=1, kernel=poly;, score=-2.441 total time=   0.0s\n",
      "[CV 5/5] END .................C=1, kernel=poly;, score=-2.560 total time=   0.0s\n",
      "[CV 1/5] END ..............C=10, kernel=linear;, score=-2.676 total time=   0.0s\n",
      "[CV 2/5] END ..............C=10, kernel=linear;, score=-2.880 total time=   0.0s\n",
      "[CV 3/5] END ..............C=10, kernel=linear;, score=-2.630 total time=   0.0s\n",
      "[CV 4/5] END ..............C=10, kernel=linear;, score=-2.441 total time=   0.0s\n",
      "[CV 5/5] END ..............C=10, kernel=linear;, score=-2.560 total time=   0.0s\n",
      "[CV 1/5] END .................C=10, kernel=rbf;, score=-2.686 total time=   0.1s\n",
      "[CV 2/5] END .................C=10, kernel=rbf;, score=-2.801 total time=   0.0s\n",
      "[CV 3/5] END .................C=10, kernel=rbf;, score=-2.630 total time=   0.1s\n",
      "[CV 4/5] END .................C=10, kernel=rbf;, score=-2.429 total time=   0.1s\n",
      "[CV 5/5] END .................C=10, kernel=rbf;, score=-2.528 total time=   0.1s\n",
      "[CV 1/5] END ................C=10, kernel=poly;, score=-2.817 total time=   0.1s\n",
      "[CV 2/5] END ................C=10, kernel=poly;, score=-2.801 total time=   0.1s\n",
      "[CV 3/5] END ................C=10, kernel=poly;, score=-2.652 total time=   0.1s\n",
      "[CV 4/5] END ................C=10, kernel=poly;, score=-2.488 total time=   0.1s\n",
      "[CV 5/5] END ................C=10, kernel=poly;, score=-2.486 total time=   0.1s\n"
     ]
    }
   ],
   "source": [
    "SVM_updrs4=pred(X_tr_scaled_UPDRS4, y_train.updrs_4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "1de9ba31",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'UPDRS_1': -6.866021647567303, 'UPDRS_2': -6.4134475293561195, 'UPDRS_3': -13.706821256295111, 'UPDRS_4': -2.6147939983340622}\n"
     ]
    }
   ],
   "source": [
    "RMSE_SVM={\"UPDRS_1\":SVM_updrs1[1],\"UPDRS_2\":SVM_updrs2[1],\"UPDRS_3\":SVM_updrs3[1],\"UPDRS_4\":SVM_updrs4[1]}\n",
    "print(RMSE_SVM)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c4a1ab9",
   "metadata": {},
   "source": [
    "Compare RMSE of light GBM with SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "216a5f81",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'UPDRS_1': -4.863244009191125, 'UPDRS_2': -4.90309557004587, 'UPDRS_3': -9.999972075310824, 'UPDRS_4': -2.2070769267466606}\n"
     ]
    }
   ],
   "source": [
    "print(RMSE_lightgbm)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "56fa0d76",
   "metadata": {},
   "source": [
    "The RMSE for light GBM is much smaller than SVM."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "94e488e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train[\"patient_status\"]=X_train[\"visit_month_diff_min\"].apply(lambda x: \"Less_severe\" if x==12 else \"Severe\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d4b7073",
   "metadata": {},
   "source": [
    "We will now look into logistic regression and see whether that could improve the RMSE. Logistic regression involves categorical response variables. We will consider each score to be high or low based on the median cut-off and use features to predict the categories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "7326ea45",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train[\"updrs1_category\"]=y_train[\"updrs_1\"].apply(lambda x: 0 if x>y_train.updrs_1.mean() else 1)\n",
    "y_train[\"updrs2_category\"]=y_train[\"updrs_2\"].apply(lambda x: 0 if x>y_train.updrs_2.mean() else 1)\n",
    "y_train[\"updrs3_category\"]=y_train[\"updrs_3\"].apply(lambda x: 0 if x>y_train.updrs_3.mean() else 1)\n",
    "y_train[\"updrs4_category\"]=y_train[\"updrs_4\"].apply(lambda x: 0 if x>y_train.updrs_4.mean() else 1)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0dd0ad66",
   "metadata": {},
   "source": [
    "We will now use grid search using C which is strength of regularization "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "249ce580",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tuned hyperparameters :(best parameters)  {'C': 0.01}\n",
      "accuracy for UPDRS1 : 0.6497795803209312\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "grid={\"C\":np.logspace(-3,3,7)}\n",
    "logreg=LogisticRegression()\n",
    "logreg_cv=GridSearchCV(logreg,grid,cv=10)\n",
    "logreg_cv.fit(X_tr_scaled_UPDRS1,y_train.updrs1_category)\n",
    "\n",
    "print(\"tuned hyperparameters :(best parameters) \",logreg_cv.best_params_)\n",
    "print(\"accuracy for UPDRS1 :\",logreg_cv.best_score_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "f4dbe5ed",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tuned hyperparameters :(best parameters)  {'C': 0.01}\n",
      "accuracy for UPDRS1 : 0.680700052900723\n"
     ]
    }
   ],
   "source": [
    "logreg_cv.fit(X_tr_scaled_UPDRS2,y_train.updrs2_category)\n",
    "print(\"tuned hyperparameters :(best parameters) \",logreg_cv.best_params_)\n",
    "print(\"accuracy for UPDRS1 :\",logreg_cv.best_score_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "0ffe0f9e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tuned hyperparameters :(best parameters)  {'C': 0.1}\n",
      "accuracy for UPDRS1 : 0.72093986951155\n"
     ]
    }
   ],
   "source": [
    "logreg_cv.fit(X_tr_scaled_UPDRS3,y_train.updrs3_category)\n",
    "print(\"tuned hyperparameters :(best parameters) \",logreg_cv.best_params_)\n",
    "print(\"accuracy for UPDRS1 :\",logreg_cv.best_score_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "0fbfd578",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tuned hyperparameters :(best parameters)  {'C': 10.0}\n",
      "accuracy for UPDRS1 : 0.8136836536766003\n"
     ]
    }
   ],
   "source": [
    "logreg_cv.fit(X_tr_scaled_UPDRS4,y_train.updrs4_category)\n",
    "print(\"tuned hyperparameters :(best parameters) \",logreg_cv.best_params_)\n",
    "print(\"accuracy for UPDRS1 :\",logreg_cv.best_score_)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "006b3b09",
   "metadata": {},
   "source": [
    "When we look at accuracy based on using categories rather than scores, the accuracy is better than a random 50%. For UPDRS3 and UPDRS4 scores, the accuracy is above 70%. While for UPDRS1 and UPDRS2 it is 65% and 68% respctively. Predicting categories rather than scores is simpler and our features for each score do better. "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
