{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e268675c",
   "metadata": {},
   "source": [
    "# Modeling "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a861268a",
   "metadata": {},
   "source": [
    "In this notebook, we will be predicting the different UPDRS scores for the patients at each time point. We will be using the selected features from Boruta for the predictions. We will be using three different models light gbm, SVM and logistic regression and testing which one works best and gives the most optimal results. The reason that we chose light gbm rather than traditional gradient boosting models or random forest is its faster training time and higher accuracy. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b5b53ba",
   "metadata": {},
   "source": [
    "Load the libraries "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "75a0a4a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "import numpy as np\n",
    "from numpy import arange\n",
    "import pandas as pd\n",
    "import lightgbm\n",
    "from lightgbm import LGBMClassifier\n",
    "from bayes_opt import BayesianOptimization\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.model_selection import GridSearchCV, RepeatedKFold\n",
    "from sklearn.metrics import accuracy_score, f1_score\n",
    "from sklearn.svm import SVC\n",
    "from tabulate import tabulate"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a5d22da8",
   "metadata": {},
   "source": [
    "Load the training and test datasets "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c3fb9314",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train=pd.read_csv(\"X_train.csv\",index_col=0)\n",
    "y_train=pd.read_csv('y_train.csv',index_col=0)\n",
    "X_test=pd.read_csv(\"X_test.csv\")\n",
    "y_test=pd.read_csv('y_test.csv')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d054b6e",
   "metadata": {},
   "source": [
    "Load the selected protein and peptide abundances which are important for each of the UPDRS scores based on the boruta algorithm."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1708f94a",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "features_UPDRS1=pd.read_csv(\"features_UPDRS1\",header=None)\n",
    "features_UPDRS2=pd.read_csv(\"features_UPDRS2\",header=None)\n",
    "features_UPDRS3=pd.read_csv(\"features_UPDRS3\",header=None)\n",
    "features_UPDRS4=pd.read_csv(\"features_UPDRS4\",header=None)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af86aacd",
   "metadata": {},
   "source": [
    "We will be modelling each of the developed UPDRS scores seperately with a light gbm model and doing hyper parameter tuning to get the parameters with the best cross validation. We will be using bayesian optimization for hyperparameter tuning when using lightgbm with five fold cross validation. Bayesian Optimization is performed over the specified search space (params_bounds) for a number of initial points (init_points) and iterations (n_iter).Apply the Bayesian optimizer to the function we created in the previous step to identify the best hyperparameters. We will run 10 iterations and set init_points = 2."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "91c28209",
   "metadata": {},
   "source": [
    "We will first be selecting the UPDRS 1 features only for X_train and then predicting the UPDRS 1 scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f172cf54",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0                                              2\n",
       "1                                             25\n",
       "2                                             89\n",
       "3                                            229\n",
       "4                                            839\n",
       "5    upd23b_clinical_state_on_medication_Unknown\n",
       "Name: 0, dtype: object"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "features_UPDRS1.loc[:,0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "59ff47ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_UPDRS1=X_train[features_UPDRS1.loc[:,0].tolist()]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10667b38",
   "metadata": {},
   "source": [
    "**We will now be defining a function for five fold cross-validation with light gbm and apply it to each of the scores. The accuracy metric that we will be using is  RMSE (root mean square error), which measures the average difference between the values predicted by the model compared to the actual values. The RMSE score reported by scikit-learn's scoring mechanism is negative to ensure higher values still indicate better models. R2 values are another metric that can be used which is a scaled version of RMSE from 0 to 1. However, lightgbm regression did not have R2 as a metric so we used RMSE "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "67ecc872",
   "metadata": {},
   "outputs": [],
   "source": [
    "def lgb_bayes_optimize(X_train, y_train):\n",
    "    # Define the evaluation function for Bayesian Optimization\n",
    "    def lgb_eval(num_leaves, max_depth, lambda_l2, lambda_l1, min_child_samples, min_data_in_leaf):\n",
    "        params = {\"objective\" : \"regression\",\"metric\" : \"RMSE\",'is_unbalance': True,\"num_leaves\" : int(num_leaves), \"max_depth\" : int(max_depth),\n",
    " \"lambda_l2\" : lambda_l2,\"lambda_l1\" : lambda_l1,\"num_threads\" : 20, \"min_child_samples\" : int(min_child_samples), 'min_data_in_leaf': int(min_data_in_leaf),\n",
    "\"learning_rate\" : 0.03, \"subsample_freq\" : 5,\"verbosity\" : -1}\n",
    " # Create LightGBM datasets\n",
    "        lgtrain = lightgbm.Dataset(X_train, y_train)\n",
    "# Perform cross-validation with early stopping\n",
    "        cv_result = lightgbm.cv(params,\n",
    "                       lgtrain,\n",
    "                        num_boost_round=100,\n",
    "                       stratified=False, callbacks=[ lightgbm.early_stopping(stopping_rounds=1000),], nfold=3)\n",
    "        \n",
    "        # Return the negative RMSE to be maximized by Bayesian Optimization\n",
    "        return -1.0 * cv_result['valid rmse-mean'][-1]\n",
    "\n",
    "    # Define the search space for Bayesian Optimization\n",
    "    params_bounds = {\n",
    "        'num_leaves': (25, 4000),\n",
    "        'max_depth': (5, 63),\n",
    "        'lambda_l2': (0.0, 0.05),\n",
    "        'lambda_l1': (0.0, 0.05),\n",
    "        'min_child_samples': (50, 10000),\n",
    "        'min_data_in_leaf': (100, 2000)\n",
    "    }\n",
    "    \n",
    "    # Initialize Bayesian Optimization\n",
    "    lgbBO = BayesianOptimization(lgb_eval, params_bounds, random_state=42)\n",
    "\n",
    "    # Perform Bayesian Optimization\n",
    "    lgbBO.maximize(init_points=2, n_iter=10)\n",
    "\n",
    "    # Get the best parameters\n",
    "    best_params = lgbBO.max['params']\n",
    "    #Get rmse\n",
    "    rmse= lgbBO.max['target']\n",
    "       \n",
    "    return  best_params, rmse"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "218b6ecf",
   "metadata": {},
   "source": [
    "Train light gbm wth cross validation and hyperparameter tuning for UPDRS_1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c90dbdae",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "|   iter    |  target   | lambda_l1 | lambda_l2 | max_depth | min_ch... | min_da... | num_le... |\n",
      "-------------------------------------------------------------------------------------------------\n",
      "Training until validation scores don't improve for 1000 rounds\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[1]\tcv_agg's valid rmse: 5.27547 + 0.114277\n",
      "| \u001b[0m1        \u001b[0m | \u001b[0m-5.275   \u001b[0m | \u001b[0m0.01873  \u001b[0m | \u001b[0m0.04754  \u001b[0m | \u001b[0m47.46    \u001b[0m | \u001b[0m6.007e+03\u001b[0m | \u001b[0m396.4    \u001b[0m | \u001b[0m645.1    \u001b[0m |\n",
      "Training until validation scores don't improve for 1000 rounds\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[98]\tcv_agg's valid rmse: 4.75044 + 0.16736\n",
      "| \u001b[95m2        \u001b[0m | \u001b[95m-4.75    \u001b[0m | \u001b[95m0.002904 \u001b[0m | \u001b[95m0.04331  \u001b[0m | \u001b[95m39.86    \u001b[0m | \u001b[95m7.095e+03\u001b[0m | \u001b[95m139.1    \u001b[0m | \u001b[95m3.88e+03 \u001b[0m |\n",
      "Training until validation scores don't improve for 1000 rounds\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[1]\tcv_agg's valid rmse: 5.27547 + 0.114277\n",
      "| \u001b[0m3        \u001b[0m | \u001b[0m-5.275   \u001b[0m | \u001b[0m0.03768  \u001b[0m | \u001b[0m0.04288  \u001b[0m | \u001b[0m39.23    \u001b[0m | \u001b[0m3.695e+03\u001b[0m | \u001b[0m937.8    \u001b[0m | \u001b[0m3.15e+03 \u001b[0m |\n",
      "Training until validation scores don't improve for 1000 rounds\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[1]\tcv_agg's valid rmse: 5.27547 + 0.114277\n",
      "| \u001b[0m4        \u001b[0m | \u001b[0m-5.275   \u001b[0m | \u001b[0m0.00621  \u001b[0m | \u001b[0m0.03564  \u001b[0m | \u001b[0m47.96    \u001b[0m | \u001b[0m1.606e+03\u001b[0m | \u001b[0m1.304e+03\u001b[0m | \u001b[0m3.542e+03\u001b[0m |\n",
      "Training until validation scores don't improve for 1000 rounds\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[77]\tcv_agg's valid rmse: 4.75603 + 0.144313\n",
      "| \u001b[0m5        \u001b[0m | \u001b[0m-4.756   \u001b[0m | \u001b[0m0.03142  \u001b[0m | \u001b[0m0.002444 \u001b[0m | \u001b[0m13.47    \u001b[0m | \u001b[0m8.131e+03\u001b[0m | \u001b[0m100.5    \u001b[0m | \u001b[0m3.998e+03\u001b[0m |\n",
      "Training until validation scores don't improve for 1000 rounds\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[1]\tcv_agg's valid rmse: 5.27547 + 0.114277\n",
      "| \u001b[0m6        \u001b[0m | \u001b[0m-5.275   \u001b[0m | \u001b[0m0.01624  \u001b[0m | \u001b[0m0.03727  \u001b[0m | \u001b[0m63.0     \u001b[0m | \u001b[0m8.042e+03\u001b[0m | \u001b[0m2e+03    \u001b[0m | \u001b[0m4e+03    \u001b[0m |\n",
      "Training until validation scores don't improve for 1000 rounds\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[1]\tcv_agg's valid rmse: 5.27547 + 0.114277\n",
      "| \u001b[0m7        \u001b[0m | \u001b[0m-5.275   \u001b[0m | \u001b[0m0.02189  \u001b[0m | \u001b[0m0.008072 \u001b[0m | \u001b[0m13.14    \u001b[0m | \u001b[0m65.09    \u001b[0m | \u001b[0m1.996e+03\u001b[0m | \u001b[0m2.143e+03\u001b[0m |\n",
      "Training until validation scores don't improve for 1000 rounds\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[77]\tcv_agg's valid rmse: 4.75602 + 0.144321\n",
      "| \u001b[0m8        \u001b[0m | \u001b[0m-4.756   \u001b[0m | \u001b[0m0.01222  \u001b[0m | \u001b[0m0.03804  \u001b[0m | \u001b[0m5.0      \u001b[0m | \u001b[0m7.825e+03\u001b[0m | \u001b[0m100.0    \u001b[0m | \u001b[0m2.812e+03\u001b[0m |\n",
      "Training until validation scores don't improve for 1000 rounds\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[95]\tcv_agg's valid rmse: 5.10427 + 0.265136\n",
      "| \u001b[0m9        \u001b[0m | \u001b[0m-5.104   \u001b[0m | \u001b[0m0.02094  \u001b[0m | \u001b[0m0.03627  \u001b[0m | \u001b[0m35.22    \u001b[0m | \u001b[0m7.43e+03 \u001b[0m | \u001b[0m248.6    \u001b[0m | \u001b[0m155.0    \u001b[0m |\n",
      "Training until validation scores don't improve for 1000 rounds\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[94]\tcv_agg's valid rmse: 4.74498 + 0.17483\n",
      "| \u001b[95m10       \u001b[0m | \u001b[95m-4.745   \u001b[0m | \u001b[95m0.01405  \u001b[0m | \u001b[95m0.01831  \u001b[0m | \u001b[95m26.27    \u001b[0m | \u001b[95m7.128e+03\u001b[0m | \u001b[95m121.7    \u001b[0m | \u001b[95m3.784e+03\u001b[0m |\n",
      "Training until validation scores don't improve for 1000 rounds\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[77]\tcv_agg's valid rmse: 4.75602 + 0.144321\n",
      "| \u001b[0m11       \u001b[0m | \u001b[0m-4.756   \u001b[0m | \u001b[0m0.04045  \u001b[0m | \u001b[0m0.03631  \u001b[0m | \u001b[0m5.0      \u001b[0m | \u001b[0m1e+04    \u001b[0m | \u001b[0m100.0    \u001b[0m | \u001b[0m1.648e+03\u001b[0m |\n",
      "Training until validation scores don't improve for 1000 rounds\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[77]\tcv_agg's valid rmse: 4.75602 + 0.144319\n",
      "| \u001b[0m12       \u001b[0m | \u001b[0m-4.756   \u001b[0m | \u001b[0m0.05     \u001b[0m | \u001b[0m0.05     \u001b[0m | \u001b[0m63.0     \u001b[0m | \u001b[0m1e+04    \u001b[0m | \u001b[0m100.0    \u001b[0m | \u001b[0m3.507e+03\u001b[0m |\n",
      "=================================================================================================\n",
      "Best parameters found for UPDRS1: {'lambda_l1': 0.014054041040552134, 'lambda_l2': 0.018307674033779177, 'max_depth': 26.27463091598586, 'min_child_samples': 7127.5209284143175, 'min_data_in_leaf': 121.68326687883841, 'num_leaves': 3784.0776005157313}\n",
      "RMSE for UPDRS1 -4.744981175550429\n"
     ]
    }
   ],
   "source": [
    "best_params, rmse = lgb_bayes_optimize(X_train_UPDRS1,y_train.updrs_1)\n",
    "\n",
    "print(\"Best parameters found for UPDRS1:\", best_params)\n",
    "print(\"RMSE for UPDRS1\", rmse)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7117c25",
   "metadata": {},
   "source": [
    "We would like to see the best parameters and the mean RMSE for the training dataset prediction of UPDRS_1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a91f1ec1",
   "metadata": {},
   "source": [
    "After cross validation the RMSE  4.74."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69ad9cf1",
   "metadata": {},
   "source": [
    "Let me see if the same model with UPDRS associated boruta associated features  works well for cross validation for the other UPDRS scores."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "1df3dbc3",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_UPDRS2=X_train[features_UPDRS2.loc[:,0].tolist()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "bbc21b5c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "|   iter    |  target   | lambda_l1 | lambda_l2 | max_depth | min_ch... | min_da... | num_le... |\n",
      "-------------------------------------------------------------------------------------------------\n",
      "Training until validation scores don't improve for 1000 rounds\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[1]\tcv_agg's valid rmse: 5.91598 + 0.097993\n",
      "| \u001b[0m1        \u001b[0m | \u001b[0m-5.916   \u001b[0m | \u001b[0m0.01873  \u001b[0m | \u001b[0m0.04754  \u001b[0m | \u001b[0m47.46    \u001b[0m | \u001b[0m6.007e+03\u001b[0m | \u001b[0m396.4    \u001b[0m | \u001b[0m645.1    \u001b[0m |\n",
      "Training until validation scores don't improve for 1000 rounds\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[100]\tcv_agg's valid rmse: 4.64158 + 0.128303\n",
      "| \u001b[95m2        \u001b[0m | \u001b[95m-4.642   \u001b[0m | \u001b[95m0.002904 \u001b[0m | \u001b[95m0.04331  \u001b[0m | \u001b[95m39.86    \u001b[0m | \u001b[95m7.095e+03\u001b[0m | \u001b[95m139.1    \u001b[0m | \u001b[95m3.88e+03 \u001b[0m |\n",
      "Training until validation scores don't improve for 1000 rounds\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[1]\tcv_agg's valid rmse: 5.91598 + 0.097993\n",
      "| \u001b[0m3        \u001b[0m | \u001b[0m-5.916   \u001b[0m | \u001b[0m0.03768  \u001b[0m | \u001b[0m0.04288  \u001b[0m | \u001b[0m39.23    \u001b[0m | \u001b[0m3.695e+03\u001b[0m | \u001b[0m937.8    \u001b[0m | \u001b[0m3.15e+03 \u001b[0m |\n",
      "Training until validation scores don't improve for 1000 rounds\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[1]\tcv_agg's valid rmse: 5.91598 + 0.097993\n",
      "| \u001b[0m4        \u001b[0m | \u001b[0m-5.916   \u001b[0m | \u001b[0m0.00621  \u001b[0m | \u001b[0m0.03564  \u001b[0m | \u001b[0m47.96    \u001b[0m | \u001b[0m1.606e+03\u001b[0m | \u001b[0m1.304e+03\u001b[0m | \u001b[0m3.542e+03\u001b[0m |\n",
      "Training until validation scores don't improve for 1000 rounds\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[100]\tcv_agg's valid rmse: 4.95817 + 0.112545\n",
      "| \u001b[0m5        \u001b[0m | \u001b[0m-4.958   \u001b[0m | \u001b[0m0.03901  \u001b[0m | \u001b[0m0.0274   \u001b[0m | \u001b[0m7.125    \u001b[0m | \u001b[0m8.113e+03\u001b[0m | \u001b[0m196.8    \u001b[0m | \u001b[0m3.858e+03\u001b[0m |\n",
      "Training until validation scores don't improve for 1000 rounds\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[1]\tcv_agg's valid rmse: 5.91598 + 0.097993\n",
      "| \u001b[0m6        \u001b[0m | \u001b[0m-5.916   \u001b[0m | \u001b[0m0.04813  \u001b[0m | \u001b[0m0.02331  \u001b[0m | \u001b[0m63.0     \u001b[0m | \u001b[0m6.965e+03\u001b[0m | \u001b[0m1.769e+03\u001b[0m | \u001b[0m4e+03    \u001b[0m |\n",
      "Training until validation scores don't improve for 1000 rounds\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[1]\tcv_agg's valid rmse: 5.91598 + 0.097993\n",
      "| \u001b[0m7        \u001b[0m | \u001b[0m-5.916   \u001b[0m | \u001b[0m0.02189  \u001b[0m | \u001b[0m0.008072 \u001b[0m | \u001b[0m13.14    \u001b[0m | \u001b[0m65.09    \u001b[0m | \u001b[0m1.996e+03\u001b[0m | \u001b[0m2.143e+03\u001b[0m |\n",
      "Training until validation scores don't improve for 1000 rounds\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[100]\tcv_agg's valid rmse: 4.57385 + 0.131439\n",
      "| \u001b[95m8        \u001b[0m | \u001b[95m-4.574   \u001b[0m | \u001b[95m0.05     \u001b[0m | \u001b[95m0.05     \u001b[0m | \u001b[95m63.0     \u001b[0m | \u001b[95m7.303e+03\u001b[0m | \u001b[95m100.0    \u001b[0m | \u001b[95m3.078e+03\u001b[0m |\n",
      "Training until validation scores don't improve for 1000 rounds\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[100]\tcv_agg's valid rmse: 5.29629 + 0.326156\n",
      "| \u001b[0m9        \u001b[0m | \u001b[0m-5.296   \u001b[0m | \u001b[0m0.02094  \u001b[0m | \u001b[0m0.03627  \u001b[0m | \u001b[0m35.22    \u001b[0m | \u001b[0m7.43e+03 \u001b[0m | \u001b[0m248.6    \u001b[0m | \u001b[0m155.0    \u001b[0m |\n",
      "Training until validation scores don't improve for 1000 rounds\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[100]\tcv_agg's valid rmse: 4.61792 + 0.161369\n",
      "| \u001b[0m10       \u001b[0m | \u001b[0m-4.618   \u001b[0m | \u001b[0m0.01405  \u001b[0m | \u001b[0m0.01831  \u001b[0m | \u001b[0m26.27    \u001b[0m | \u001b[0m7.128e+03\u001b[0m | \u001b[0m121.7    \u001b[0m | \u001b[0m3.784e+03\u001b[0m |\n",
      "Training until validation scores don't improve for 1000 rounds\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[100]\tcv_agg's valid rmse: 4.5738 + 0.131448\n",
      "| \u001b[95m11       \u001b[0m | \u001b[95m-4.574   \u001b[0m | \u001b[95m0.03343  \u001b[0m | \u001b[95m0.02643  \u001b[0m | \u001b[95m63.0     \u001b[0m | \u001b[95m1e+04    \u001b[0m | \u001b[95m100.0    \u001b[0m | \u001b[95m1.118e+03\u001b[0m |\n",
      "Training until validation scores don't improve for 1000 rounds\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[1]\tcv_agg's valid rmse: 5.91598 + 0.097993\n",
      "| \u001b[0m12       \u001b[0m | \u001b[0m-5.916   \u001b[0m | \u001b[0m0.02158  \u001b[0m | \u001b[0m0.05     \u001b[0m | \u001b[0m63.0     \u001b[0m | \u001b[0m1e+04    \u001b[0m | \u001b[0m2e+03    \u001b[0m | \u001b[0m25.0     \u001b[0m |\n",
      "=================================================================================================\n",
      "Best parameters found for UPDRS1: {'lambda_l1': 0.03342992372730768, 'lambda_l2': 0.02642645590854086, 'max_depth': 63.0, 'min_child_samples': 10000.0, 'min_data_in_leaf': 100.0, 'num_leaves': 1117.8470832670612}\n",
      "RMSE for UPDRS1 -4.573803939357066\n"
     ]
    }
   ],
   "source": [
    "\n",
    "best_params2, rmse2 = lgb_bayes_optimize(X_train_UPDRS2,y_train.updrs_2)\n",
    "\n",
    "print(\"Best parameters found for UPDRS1:\", best_params2)\n",
    "print(\"RMSE for UPDRS1\", rmse2)\n",
    "RMSE_lightgbm={\"UPDRS_2\": rmse2}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ef5eef6",
   "metadata": {},
   "source": [
    "The best RMSE for lightgbm is 4.57 for predicting UPDRS2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "91b48240",
   "metadata": {},
   "source": [
    "Let us see the performance of light gbm with UPDRS3. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "1281ac96",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_UPDRS3=X_train[features_UPDRS3.loc[:,0].tolist()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "a49f3a4d",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "|   iter    |  target   | lambda_l1 | lambda_l2 | max_depth | min_ch... | min_da... | num_le... |\n",
      "-------------------------------------------------------------------------------------------------\n",
      "Training until validation scores don't improve for 1000 rounds\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[1]\tcv_agg's valid rmse: 15.2305 + 0.122351\n",
      "| \u001b[0m1        \u001b[0m | \u001b[0m-15.23   \u001b[0m | \u001b[0m0.01873  \u001b[0m | \u001b[0m0.04754  \u001b[0m | \u001b[0m47.46    \u001b[0m | \u001b[0m6.007e+03\u001b[0m | \u001b[0m396.4    \u001b[0m | \u001b[0m645.1    \u001b[0m |\n",
      "Training until validation scores don't improve for 1000 rounds\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[100]\tcv_agg's valid rmse: 10.5285 + 0.255624\n",
      "| \u001b[95m2        \u001b[0m | \u001b[95m-10.53   \u001b[0m | \u001b[95m0.002904 \u001b[0m | \u001b[95m0.04331  \u001b[0m | \u001b[95m39.86    \u001b[0m | \u001b[95m7.095e+03\u001b[0m | \u001b[95m139.1    \u001b[0m | \u001b[95m3.88e+03 \u001b[0m |\n",
      "Training until validation scores don't improve for 1000 rounds\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[1]\tcv_agg's valid rmse: 15.2305 + 0.122351\n",
      "| \u001b[0m3        \u001b[0m | \u001b[0m-15.23   \u001b[0m | \u001b[0m0.03768  \u001b[0m | \u001b[0m0.04288  \u001b[0m | \u001b[0m39.23    \u001b[0m | \u001b[0m3.695e+03\u001b[0m | \u001b[0m937.8    \u001b[0m | \u001b[0m3.15e+03 \u001b[0m |\n",
      "Training until validation scores don't improve for 1000 rounds\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[1]\tcv_agg's valid rmse: 15.2305 + 0.122351\n",
      "| \u001b[0m4        \u001b[0m | \u001b[0m-15.23   \u001b[0m | \u001b[0m0.00621  \u001b[0m | \u001b[0m0.03564  \u001b[0m | \u001b[0m47.96    \u001b[0m | \u001b[0m1.606e+03\u001b[0m | \u001b[0m1.304e+03\u001b[0m | \u001b[0m3.542e+03\u001b[0m |\n",
      "Training until validation scores don't improve for 1000 rounds\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[100]\tcv_agg's valid rmse: 10.1696 + 0.276834\n",
      "| \u001b[95m5        \u001b[0m | \u001b[95m-10.17   \u001b[0m | \u001b[95m0.0      \u001b[0m | \u001b[95m0.05     \u001b[0m | \u001b[95m13.48    \u001b[0m | \u001b[95m8.107e+03\u001b[0m | \u001b[95m101.1    \u001b[0m | \u001b[95m4e+03    \u001b[0m |\n",
      "Training until validation scores don't improve for 1000 rounds\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[1]\tcv_agg's valid rmse: 15.2305 + 0.122351\n",
      "| \u001b[0m6        \u001b[0m | \u001b[0m-15.23   \u001b[0m | \u001b[0m0.05     \u001b[0m | \u001b[0m0.02331  \u001b[0m | \u001b[0m63.0     \u001b[0m | \u001b[0m1e+04    \u001b[0m | \u001b[0m2e+03    \u001b[0m | \u001b[0m4e+03    \u001b[0m |\n",
      "Training until validation scores don't improve for 1000 rounds\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[1]\tcv_agg's valid rmse: 15.2305 + 0.122351\n",
      "| \u001b[0m7        \u001b[0m | \u001b[0m-15.23   \u001b[0m | \u001b[0m0.02189  \u001b[0m | \u001b[0m0.008072 \u001b[0m | \u001b[0m13.14    \u001b[0m | \u001b[0m65.09    \u001b[0m | \u001b[0m1.996e+03\u001b[0m | \u001b[0m2.143e+03\u001b[0m |\n",
      "Training until validation scores don't improve for 1000 rounds\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[100]\tcv_agg's valid rmse: 10.176 + 0.27295\n",
      "| \u001b[0m8        \u001b[0m | \u001b[0m-10.18   \u001b[0m | \u001b[0m0.0      \u001b[0m | \u001b[0m0.0      \u001b[0m | \u001b[0m5.0      \u001b[0m | \u001b[0m8.302e+03\u001b[0m | \u001b[0m100.0    \u001b[0m | \u001b[0m2.544e+03\u001b[0m |\n",
      "Training until validation scores don't improve for 1000 rounds\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[100]\tcv_agg's valid rmse: 12.498 + 1.00902\n",
      "| \u001b[0m9        \u001b[0m | \u001b[0m-12.5    \u001b[0m | \u001b[0m0.02094  \u001b[0m | \u001b[0m0.03627  \u001b[0m | \u001b[0m35.22    \u001b[0m | \u001b[0m7.43e+03 \u001b[0m | \u001b[0m248.6    \u001b[0m | \u001b[0m155.0    \u001b[0m |\n",
      "Training until validation scores don't improve for 1000 rounds\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[100]\tcv_agg's valid rmse: 10.3871 + 0.37125\n",
      "| \u001b[0m10       \u001b[0m | \u001b[0m-10.39   \u001b[0m | \u001b[0m0.01405  \u001b[0m | \u001b[0m0.01831  \u001b[0m | \u001b[0m26.27    \u001b[0m | \u001b[0m7.128e+03\u001b[0m | \u001b[0m121.7    \u001b[0m | \u001b[0m3.784e+03\u001b[0m |\n",
      "Training until validation scores don't improve for 1000 rounds\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[100]\tcv_agg's valid rmse: 10.1779 + 0.270775\n",
      "| \u001b[0m11       \u001b[0m | \u001b[0m-10.18   \u001b[0m | \u001b[0m0.05     \u001b[0m | \u001b[0m0.0      \u001b[0m | \u001b[0m5.0      \u001b[0m | \u001b[0m1e+04    \u001b[0m | \u001b[0m100.0    \u001b[0m | \u001b[0m25.0     \u001b[0m |\n",
      "Training until validation scores don't improve for 1000 rounds\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[1]\tcv_agg's valid rmse: 15.2305 + 0.122351\n",
      "| \u001b[0m12       \u001b[0m | \u001b[0m-15.23   \u001b[0m | \u001b[0m0.0      \u001b[0m | \u001b[0m0.05     \u001b[0m | \u001b[0m5.0      \u001b[0m | \u001b[0m1e+04    \u001b[0m | \u001b[0m2e+03    \u001b[0m | \u001b[0m25.0     \u001b[0m |\n",
      "=================================================================================================\n",
      "Best parameters found for UPDRS1: {'lambda_l1': 0.03342992372730768, 'lambda_l2': 0.02642645590854086, 'max_depth': 63.0, 'min_child_samples': 10000.0, 'min_data_in_leaf': 100.0, 'num_leaves': 1117.8470832670612}\n",
      "RMSE for UPDRS3 -10.169609133540808\n"
     ]
    }
   ],
   "source": [
    "\n",
    "best_params3, rmse3 = lgb_bayes_optimize(X_train_UPDRS3,y_train.updrs_3)\n",
    "\n",
    "print(\"Best parameters found for UPDRS1:\", best_params2)\n",
    "print(\"RMSE for UPDRS3\", rmse3)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fdf60de8",
   "metadata": {},
   "source": [
    "\n",
    " The best RMSE for UPDRS3 is 10.16"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "43dfa2cf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "|   iter    |  target   | lambda_l1 | lambda_l2 | max_depth | min_ch... | min_da... | num_le... |\n",
      "-------------------------------------------------------------------------------------------------\n",
      "Training until validation scores don't improve for 1000 rounds\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[1]\tcv_agg's valid rmse: 2.31581 + 0.147733\n",
      "| \u001b[0m1        \u001b[0m | \u001b[0m-2.316   \u001b[0m | \u001b[0m0.01873  \u001b[0m | \u001b[0m0.04754  \u001b[0m | \u001b[0m47.46    \u001b[0m | \u001b[0m6.007e+03\u001b[0m | \u001b[0m396.4    \u001b[0m | \u001b[0m645.1    \u001b[0m |\n",
      "Training until validation scores don't improve for 1000 rounds\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[100]\tcv_agg's valid rmse: 2.03066 + 0.12377\n",
      "| \u001b[95m2        \u001b[0m | \u001b[95m-2.031   \u001b[0m | \u001b[95m0.002904 \u001b[0m | \u001b[95m0.04331  \u001b[0m | \u001b[95m39.86    \u001b[0m | \u001b[95m7.095e+03\u001b[0m | \u001b[95m139.1    \u001b[0m | \u001b[95m3.88e+03 \u001b[0m |\n",
      "Training until validation scores don't improve for 1000 rounds\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[1]\tcv_agg's valid rmse: 2.31581 + 0.147733\n",
      "| \u001b[0m3        \u001b[0m | \u001b[0m-2.316   \u001b[0m | \u001b[0m0.03768  \u001b[0m | \u001b[0m0.04288  \u001b[0m | \u001b[0m39.23    \u001b[0m | \u001b[0m3.695e+03\u001b[0m | \u001b[0m937.8    \u001b[0m | \u001b[0m3.15e+03 \u001b[0m |\n",
      "Training until validation scores don't improve for 1000 rounds\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[1]\tcv_agg's valid rmse: 2.31581 + 0.147733\n",
      "| \u001b[0m4        \u001b[0m | \u001b[0m-2.316   \u001b[0m | \u001b[0m0.00621  \u001b[0m | \u001b[0m0.03564  \u001b[0m | \u001b[0m47.96    \u001b[0m | \u001b[0m1.606e+03\u001b[0m | \u001b[0m1.304e+03\u001b[0m | \u001b[0m3.542e+03\u001b[0m |\n",
      "Training until validation scores don't improve for 1000 rounds\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[100]\tcv_agg's valid rmse: 2.05079 + 0.127121\n",
      "| \u001b[0m5        \u001b[0m | \u001b[0m-2.051   \u001b[0m | \u001b[0m0.03901  \u001b[0m | \u001b[0m0.0274   \u001b[0m | \u001b[0m7.125    \u001b[0m | \u001b[0m8.113e+03\u001b[0m | \u001b[0m196.8    \u001b[0m | \u001b[0m3.858e+03\u001b[0m |\n",
      "Training until validation scores don't improve for 1000 rounds\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[1]\tcv_agg's valid rmse: 2.31581 + 0.147733\n",
      "| \u001b[0m6        \u001b[0m | \u001b[0m-2.316   \u001b[0m | \u001b[0m0.05     \u001b[0m | \u001b[0m0.02331  \u001b[0m | \u001b[0m63.0     \u001b[0m | \u001b[0m7.445e+03\u001b[0m | \u001b[0m2e+03    \u001b[0m | \u001b[0m4e+03    \u001b[0m |\n",
      "Training until validation scores don't improve for 1000 rounds\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[1]\tcv_agg's valid rmse: 2.31581 + 0.147733\n",
      "| \u001b[0m7        \u001b[0m | \u001b[0m-2.316   \u001b[0m | \u001b[0m0.02189  \u001b[0m | \u001b[0m0.008072 \u001b[0m | \u001b[0m13.14    \u001b[0m | \u001b[0m65.09    \u001b[0m | \u001b[0m1.996e+03\u001b[0m | \u001b[0m2.143e+03\u001b[0m |\n",
      "Training until validation scores don't improve for 1000 rounds\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[96]\tcv_agg's valid rmse: 2.04335 + 0.119842\n",
      "| \u001b[0m8        \u001b[0m | \u001b[0m-2.043   \u001b[0m | \u001b[0m0.04817  \u001b[0m | \u001b[0m0.0      \u001b[0m | \u001b[0m25.08    \u001b[0m | \u001b[0m7.578e+03\u001b[0m | \u001b[0m100.0    \u001b[0m | \u001b[0m2.817e+03\u001b[0m |\n",
      "Training until validation scores don't improve for 1000 rounds\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[67]\tcv_agg's valid rmse: 2.22202 + 0.262605\n",
      "| \u001b[0m9        \u001b[0m | \u001b[0m-2.222   \u001b[0m | \u001b[0m0.02094  \u001b[0m | \u001b[0m0.03627  \u001b[0m | \u001b[0m35.22    \u001b[0m | \u001b[0m7.43e+03 \u001b[0m | \u001b[0m248.6    \u001b[0m | \u001b[0m155.0    \u001b[0m |\n",
      "Training until validation scores don't improve for 1000 rounds\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[100]\tcv_agg's valid rmse: 2.03675 + 0.114357\n",
      "| \u001b[0m10       \u001b[0m | \u001b[0m-2.037   \u001b[0m | \u001b[0m0.01405  \u001b[0m | \u001b[0m0.01831  \u001b[0m | \u001b[0m26.27    \u001b[0m | \u001b[0m7.128e+03\u001b[0m | \u001b[0m121.7    \u001b[0m | \u001b[0m3.784e+03\u001b[0m |\n",
      "Training until validation scores don't improve for 1000 rounds\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[96]\tcv_agg's valid rmse: 2.04367 + 0.119936\n",
      "| \u001b[0m11       \u001b[0m | \u001b[0m-2.044   \u001b[0m | \u001b[0m0.0      \u001b[0m | \u001b[0m0.05     \u001b[0m | \u001b[0m63.0     \u001b[0m | \u001b[0m9.523e+03\u001b[0m | \u001b[0m100.0    \u001b[0m | \u001b[0m2.025e+03\u001b[0m |\n",
      "Training until validation scores don't improve for 1000 rounds\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[1]\tcv_agg's valid rmse: 2.31581 + 0.147733\n",
      "| \u001b[0m12       \u001b[0m | \u001b[0m-2.316   \u001b[0m | \u001b[0m0.04581  \u001b[0m | \u001b[0m0.007048 \u001b[0m | \u001b[0m17.64    \u001b[0m | \u001b[0m9.933e+03\u001b[0m | \u001b[0m1.951e+03\u001b[0m | \u001b[0m475.2    \u001b[0m |\n",
      "=================================================================================================\n",
      "Best parameters found for UPDRS4: {'lambda_l1': 0.002904180608409973, 'lambda_l2': 0.04330880728874676, 'max_depth': 39.86467068110611, 'min_child_samples': 7095.322149070653, 'min_data_in_leaf': 139.11053916202465, 'num_leaves': 3880.3916623439272}\n",
      "RMSE for UPDRS4 -2.0306641374085834\n"
     ]
    }
   ],
   "source": [
    "X_train_UPDRS4=X_train[features_UPDRS4.loc[:,0].tolist()]\n",
    "\n",
    "\n",
    "best_params4, rmse4 = lgb_bayes_optimize(X_train_UPDRS4,y_train.updrs_4)\n",
    "\n",
    "print(\"Best parameters found for UPDRS4:\", best_params4)\n",
    "print(\"RMSE for UPDRS4\", rmse4)\n",
    "RMSE_lightgbm={\"UPDRS_4\": rmse4}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a8c02250",
   "metadata": {},
   "source": [
    " The best RMSE for UPDRS4 is 2.03"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "08dc420f",
   "metadata": {},
   "source": [
    "The RMSE values are very high and show that the target variables are not being predicted by the selected features. In general the RMSE should be within 10% of the mean. When we look at the RMSE we can see that our RMSE are very high meaning that the features show little trend in predicting the UPDRS scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "3add3654",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'UPDRS1': 6.478922716627634, 'UPDRS2': 5.740046838407494, 'UPDRS3': 17.50936768149883, 'UPDRS4': 0.9637002341920374}\n",
      "{'UPDRS_1': -4.744981175550429, 'UPDRS_2': -4.573803939357066, 'UPDRS_3': -10.169609133540808, 'UPDRS_4': -2.0306641374085834}\n"
     ]
    }
   ],
   "source": [
    "Mean_UPDRSscores={\"UPDRS1\":y_train.updrs_1.mean(),\"UPDRS2\":y_train.updrs_2.mean(),\"UPDRS3\":y_train.updrs_3.mean(),\"UPDRS4\":y_train.updrs_4.mean()}\n",
    "RMSE_lightgbm={\"UPDRS_1\": rmse,\"UPDRS_2\": rmse2,\"UPDRS_3\": rmse3,\"UPDRS_4\": rmse4}\n",
    "print(Mean_UPDRSscores)\n",
    "print(RMSE_lightgbm)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4322934b",
   "metadata": {},
   "source": [
    "**Let me see how elastic net regression performs in cross validation in RMSE using the same features that we used for prediction for each of the UPDRS scores. We will be doing five fold cross validation using grid search for hyper parameter tuning looking at different kernels and regularization parameter C. We can do an exhaustive search using grid search looking at all possible combinations rather than a smart bayesian based approach as we have fewer parameters to tune."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "158b5b88",
   "metadata": {},
   "outputs": [],
   "source": [
    "def pred(x,y):\n",
    "    param_grid = {'C': [0.1, 1, 10], 'kernel': ['linear', 'rbf', 'poly']}\n",
    "    grid = GridSearchCV(SVC(), param_grid, refit = True, verbose = 3,scoring=\"neg_root_mean_squared_error\") \n",
    "  # fitting the models for grid search \n",
    "    grid.fit(x, y) \n",
    "    best_params = grid.best_params_\n",
    "    best_score = grid.best_score_\n",
    "    return(best_params,best_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "5ca44129",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 9 candidates, totalling 45 fits\n",
      "[CV 1/5] END .............C=0.1, kernel=linear;, score=-6.350 total time=   0.1s\n",
      "[CV 2/5] END .............C=0.1, kernel=linear;, score=-6.039 total time=   0.0s\n",
      "[CV 3/5] END .............C=0.1, kernel=linear;, score=-5.566 total time=   0.0s\n",
      "[CV 4/5] END .............C=0.1, kernel=linear;, score=-6.369 total time=   0.0s\n",
      "[CV 5/5] END .............C=0.1, kernel=linear;, score=-5.612 total time=   0.0s\n",
      "[CV 1/5] END ................C=0.1, kernel=rbf;, score=-7.698 total time=   0.0s\n",
      "[CV 2/5] END ................C=0.1, kernel=rbf;, score=-7.790 total time=   0.0s\n",
      "[CV 3/5] END ................C=0.1, kernel=rbf;, score=-7.579 total time=   0.0s\n",
      "[CV 4/5] END ................C=0.1, kernel=rbf;, score=-7.612 total time=   0.0s\n",
      "[CV 5/5] END ................C=0.1, kernel=rbf;, score=-7.328 total time=   0.0s\n",
      "[CV 1/5] END ...............C=0.1, kernel=poly;, score=-7.651 total time=   0.0s\n",
      "[CV 2/5] END ...............C=0.1, kernel=poly;, score=-7.772 total time=   0.0s\n",
      "[CV 3/5] END ...............C=0.1, kernel=poly;, score=-7.623 total time=   0.0s\n",
      "[CV 4/5] END ...............C=0.1, kernel=poly;, score=-7.530 total time=   0.0s\n",
      "[CV 5/5] END ...............C=0.1, kernel=poly;, score=-7.254 total time=   0.0s\n",
      "[CV 1/5] END ...............C=1, kernel=linear;, score=-6.282 total time=   0.0s\n",
      "[CV 2/5] END ...............C=1, kernel=linear;, score=-6.042 total time=   0.0s\n",
      "[CV 3/5] END ...............C=1, kernel=linear;, score=-5.930 total time=   0.0s\n",
      "[CV 4/5] END ...............C=1, kernel=linear;, score=-5.839 total time=   0.0s\n",
      "[CV 5/5] END ...............C=1, kernel=linear;, score=-5.455 total time=   0.0s\n",
      "[CV 1/5] END ..................C=1, kernel=rbf;, score=-6.460 total time=   0.0s\n",
      "[CV 2/5] END ..................C=1, kernel=rbf;, score=-6.226 total time=   0.0s\n",
      "[CV 3/5] END ..................C=1, kernel=rbf;, score=-6.066 total time=   0.0s\n",
      "[CV 4/5] END ..................C=1, kernel=rbf;, score=-5.976 total time=   0.0s\n",
      "[CV 5/5] END ..................C=1, kernel=rbf;, score=-5.587 total time=   0.0s\n",
      "[CV 1/5] END .................C=1, kernel=poly;, score=-7.658 total time=   0.0s\n",
      "[CV 2/5] END .................C=1, kernel=poly;, score=-7.668 total time=   0.0s\n",
      "[CV 3/5] END .................C=1, kernel=poly;, score=-5.894 total time=   0.0s\n",
      "[CV 4/5] END .................C=1, kernel=poly;, score=-7.501 total time=   0.0s\n",
      "[CV 5/5] END .................C=1, kernel=poly;, score=-7.253 total time=   0.0s\n",
      "[CV 1/5] END ..............C=10, kernel=linear;, score=-6.286 total time=   0.1s\n",
      "[CV 2/5] END ..............C=10, kernel=linear;, score=-5.992 total time=   0.1s\n",
      "[CV 3/5] END ..............C=10, kernel=linear;, score=-5.866 total time=   0.1s\n",
      "[CV 4/5] END ..............C=10, kernel=linear;, score=-5.856 total time=   0.1s\n",
      "[CV 5/5] END ..............C=10, kernel=linear;, score=-5.474 total time=   0.1s\n",
      "[CV 1/5] END .................C=10, kernel=rbf;, score=-5.964 total time=   0.0s\n",
      "[CV 2/5] END .................C=10, kernel=rbf;, score=-5.895 total time=   0.0s\n",
      "[CV 3/5] END .................C=10, kernel=rbf;, score=-5.838 total time=   0.0s\n",
      "[CV 4/5] END .................C=10, kernel=rbf;, score=-5.081 total time=   0.0s\n",
      "[CV 5/5] END .................C=10, kernel=rbf;, score=-5.303 total time=   0.0s\n",
      "[CV 1/5] END ................C=10, kernel=poly;, score=-6.310 total time=   0.0s\n",
      "[CV 2/5] END ................C=10, kernel=poly;, score=-5.672 total time=   0.0s\n",
      "[CV 3/5] END ................C=10, kernel=poly;, score=-6.122 total time=   0.0s\n",
      "[CV 4/5] END ................C=10, kernel=poly;, score=-5.512 total time=   0.0s\n",
      "[CV 5/5] END ................C=10, kernel=poly;, score=-5.318 total time=   0.0s\n"
     ]
    }
   ],
   "source": [
    "SVM_updrs1=pred(X_train_UPDRS1, y_train.updrs_1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "d8da1a7d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 9 candidates, totalling 45 fits\n",
      "[CV 1/5] END .............C=0.1, kernel=linear;, score=-6.903 total time=   0.0s\n",
      "[CV 2/5] END .............C=0.1, kernel=linear;, score=-6.856 total time=   0.0s\n",
      "[CV 3/5] END .............C=0.1, kernel=linear;, score=-7.205 total time=   0.0s\n",
      "[CV 4/5] END .............C=0.1, kernel=linear;, score=-7.294 total time=   0.0s\n",
      "[CV 5/5] END .............C=0.1, kernel=linear;, score=-6.200 total time=   0.0s\n",
      "[CV 1/5] END ................C=0.1, kernel=rbf;, score=-8.104 total time=   0.0s\n",
      "[CV 2/5] END ................C=0.1, kernel=rbf;, score=-8.180 total time=   0.0s\n",
      "[CV 3/5] END ................C=0.1, kernel=rbf;, score=-8.324 total time=   0.0s\n",
      "[CV 4/5] END ................C=0.1, kernel=rbf;, score=-8.479 total time=   0.0s\n",
      "[CV 5/5] END ................C=0.1, kernel=rbf;, score=-8.038 total time=   0.0s\n",
      "[CV 1/5] END ...............C=0.1, kernel=poly;, score=-7.919 total time=   0.0s\n",
      "[CV 2/5] END ...............C=0.1, kernel=poly;, score=-8.005 total time=   0.0s\n",
      "[CV 3/5] END ...............C=0.1, kernel=poly;, score=-8.205 total time=   0.0s\n",
      "[CV 4/5] END ...............C=0.1, kernel=poly;, score=-8.567 total time=   0.0s\n",
      "[CV 5/5] END ...............C=0.1, kernel=poly;, score=-7.514 total time=   0.0s\n",
      "[CV 1/5] END ...............C=1, kernel=linear;, score=-5.673 total time=   0.0s\n",
      "[CV 2/5] END ...............C=1, kernel=linear;, score=-6.355 total time=   0.0s\n",
      "[CV 3/5] END ...............C=1, kernel=linear;, score=-5.859 total time=   0.0s\n",
      "[CV 4/5] END ...............C=1, kernel=linear;, score=-6.550 total time=   0.0s\n",
      "[CV 5/5] END ...............C=1, kernel=linear;, score=-5.954 total time=   0.0s\n",
      "[CV 1/5] END ..................C=1, kernel=rbf;, score=-5.827 total time=   0.0s\n",
      "[CV 2/5] END ..................C=1, kernel=rbf;, score=-6.225 total time=   0.0s\n",
      "[CV 3/5] END ..................C=1, kernel=rbf;, score=-6.437 total time=   0.0s\n",
      "[CV 4/5] END ..................C=1, kernel=rbf;, score=-6.241 total time=   0.0s\n",
      "[CV 5/5] END ..................C=1, kernel=rbf;, score=-5.953 total time=   0.0s\n",
      "[CV 1/5] END .................C=1, kernel=poly;, score=-7.380 total time=   0.0s\n",
      "[CV 2/5] END .................C=1, kernel=poly;, score=-7.627 total time=   0.0s\n",
      "[CV 3/5] END .................C=1, kernel=poly;, score=-7.905 total time=   0.0s\n",
      "[CV 4/5] END .................C=1, kernel=poly;, score=-8.241 total time=   0.0s\n",
      "[CV 5/5] END .................C=1, kernel=poly;, score=-7.151 total time=   0.0s\n",
      "[CV 1/5] END ..............C=10, kernel=linear;, score=-5.793 total time=   0.1s\n",
      "[CV 2/5] END ..............C=10, kernel=linear;, score=-6.014 total time=   0.1s\n",
      "[CV 3/5] END ..............C=10, kernel=linear;, score=-5.830 total time=   0.1s\n",
      "[CV 4/5] END ..............C=10, kernel=linear;, score=-6.476 total time=   0.1s\n",
      "[CV 5/5] END ..............C=10, kernel=linear;, score=-5.729 total time=   0.1s\n",
      "[CV 1/5] END .................C=10, kernel=rbf;, score=-5.605 total time=   0.0s\n",
      "[CV 2/5] END .................C=10, kernel=rbf;, score=-6.272 total time=   0.0s\n",
      "[CV 3/5] END .................C=10, kernel=rbf;, score=-5.707 total time=   0.0s\n",
      "[CV 4/5] END .................C=10, kernel=rbf;, score=-6.312 total time=   0.0s\n",
      "[CV 5/5] END .................C=10, kernel=rbf;, score=-4.817 total time=   0.0s\n",
      "[CV 1/5] END ................C=10, kernel=poly;, score=-5.766 total time=   0.0s\n",
      "[CV 2/5] END ................C=10, kernel=poly;, score=-6.047 total time=   0.0s\n",
      "[CV 3/5] END ................C=10, kernel=poly;, score=-6.428 total time=   0.0s\n",
      "[CV 4/5] END ................C=10, kernel=poly;, score=-6.702 total time=   0.0s\n",
      "[CV 5/5] END ................C=10, kernel=poly;, score=-5.991 total time=   0.0s\n"
     ]
    }
   ],
   "source": [
    "SVM_updrs2=pred(X_train_UPDRS2, y_train.updrs_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "9fb6e4cb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 9 candidates, totalling 45 fits\n",
      "[CV 1/5] END ............C=0.1, kernel=linear;, score=-15.334 total time=   0.0s\n",
      "[CV 2/5] END ............C=0.1, kernel=linear;, score=-16.758 total time=   0.0s\n",
      "[CV 3/5] END ............C=0.1, kernel=linear;, score=-17.904 total time=   0.0s\n",
      "[CV 4/5] END ............C=0.1, kernel=linear;, score=-15.932 total time=   0.0s\n",
      "[CV 5/5] END ............C=0.1, kernel=linear;, score=-15.285 total time=   0.0s\n",
      "[CV 1/5] END ...............C=0.1, kernel=rbf;, score=-22.246 total time=   0.1s\n",
      "[CV 2/5] END ...............C=0.1, kernel=rbf;, score=-22.871 total time=   0.1s\n",
      "[CV 3/5] END ...............C=0.1, kernel=rbf;, score=-23.719 total time=   0.1s\n",
      "[CV 4/5] END ...............C=0.1, kernel=rbf;, score=-23.460 total time=   0.1s\n",
      "[CV 5/5] END ...............C=0.1, kernel=rbf;, score=-23.544 total time=   0.1s\n",
      "[CV 1/5] END ..............C=0.1, kernel=poly;, score=-22.235 total time=   0.0s\n",
      "[CV 2/5] END ..............C=0.1, kernel=poly;, score=-22.460 total time=   0.0s\n",
      "[CV 3/5] END ..............C=0.1, kernel=poly;, score=-23.451 total time=   0.0s\n",
      "[CV 4/5] END ..............C=0.1, kernel=poly;, score=-22.793 total time=   0.0s\n",
      "[CV 5/5] END ..............C=0.1, kernel=poly;, score=-23.340 total time=   0.0s\n",
      "[CV 1/5] END ..............C=1, kernel=linear;, score=-12.667 total time=   0.1s\n",
      "[CV 2/5] END ..............C=1, kernel=linear;, score=-11.563 total time=   0.1s\n",
      "[CV 3/5] END ..............C=1, kernel=linear;, score=-12.438 total time=   0.1s\n",
      "[CV 4/5] END ..............C=1, kernel=linear;, score=-13.696 total time=   0.1s\n",
      "[CV 5/5] END ..............C=1, kernel=linear;, score=-12.478 total time=   0.1s\n",
      "[CV 1/5] END .................C=1, kernel=rbf;, score=-15.931 total time=   0.1s\n",
      "[CV 2/5] END .................C=1, kernel=rbf;, score=-16.898 total time=   0.1s\n",
      "[CV 3/5] END .................C=1, kernel=rbf;, score=-18.779 total time=   0.1s\n",
      "[CV 4/5] END .................C=1, kernel=rbf;, score=-16.899 total time=   0.1s\n",
      "[CV 5/5] END .................C=1, kernel=rbf;, score=-16.418 total time=   0.1s\n",
      "[CV 1/5] END ................C=1, kernel=poly;, score=-22.066 total time=   0.0s\n",
      "[CV 2/5] END ................C=1, kernel=poly;, score=-21.662 total time=   0.0s\n",
      "[CV 3/5] END ................C=1, kernel=poly;, score=-21.798 total time=   0.0s\n",
      "[CV 4/5] END ................C=1, kernel=poly;, score=-22.256 total time=   0.0s\n",
      "[CV 5/5] END ................C=1, kernel=poly;, score=-21.821 total time=   0.0s\n",
      "[CV 1/5] END .............C=10, kernel=linear;, score=-13.429 total time=   0.1s\n",
      "[CV 2/5] END .............C=10, kernel=linear;, score=-12.060 total time=   0.1s\n",
      "[CV 3/5] END .............C=10, kernel=linear;, score=-14.249 total time=   0.1s\n",
      "[CV 4/5] END .............C=10, kernel=linear;, score=-16.107 total time=   0.1s\n",
      "[CV 5/5] END .............C=10, kernel=linear;, score=-13.447 total time=   0.1s\n",
      "[CV 1/5] END ................C=10, kernel=rbf;, score=-13.582 total time=   0.1s\n",
      "[CV 2/5] END ................C=10, kernel=rbf;, score=-11.636 total time=   0.1s\n",
      "[CV 3/5] END ................C=10, kernel=rbf;, score=-13.192 total time=   0.1s\n",
      "[CV 4/5] END ................C=10, kernel=rbf;, score=-13.639 total time=   0.1s\n",
      "[CV 5/5] END ................C=10, kernel=rbf;, score=-12.602 total time=   0.1s\n",
      "[CV 1/5] END ...............C=10, kernel=poly;, score=-18.949 total time=   0.0s\n",
      "[CV 2/5] END ...............C=10, kernel=poly;, score=-17.941 total time=   0.0s\n",
      "[CV 3/5] END ...............C=10, kernel=poly;, score=-15.259 total time=   0.0s\n",
      "[CV 4/5] END ...............C=10, kernel=poly;, score=-17.920 total time=   0.0s\n",
      "[CV 5/5] END ...............C=10, kernel=poly;, score=-16.801 total time=   0.0s\n"
     ]
    }
   ],
   "source": [
    "SVM_updrs3=pred(X_train_UPDRS3, y_train.updrs_3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "4805dfa1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 9 candidates, totalling 45 fits\n",
      "[CV 1/5] END .............C=0.1, kernel=linear;, score=-2.320 total time=   0.0s\n",
      "[CV 2/5] END .............C=0.1, kernel=linear;, score=-2.253 total time=   0.0s\n",
      "[CV 3/5] END .............C=0.1, kernel=linear;, score=-2.682 total time=   0.0s\n",
      "[CV 4/5] END .............C=0.1, kernel=linear;, score=-2.900 total time=   0.0s\n",
      "[CV 5/5] END .............C=0.1, kernel=linear;, score=-2.405 total time=   0.0s\n",
      "[CV 1/5] END ................C=0.1, kernel=rbf;, score=-2.320 total time=   0.0s\n",
      "[CV 2/5] END ................C=0.1, kernel=rbf;, score=-2.253 total time=   0.0s\n",
      "[CV 3/5] END ................C=0.1, kernel=rbf;, score=-2.682 total time=   0.0s\n",
      "[CV 4/5] END ................C=0.1, kernel=rbf;, score=-2.900 total time=   0.0s\n",
      "[CV 5/5] END ................C=0.1, kernel=rbf;, score=-2.405 total time=   0.0s\n",
      "[CV 1/5] END ...............C=0.1, kernel=poly;, score=-2.320 total time=   0.0s\n",
      "[CV 2/5] END ...............C=0.1, kernel=poly;, score=-2.253 total time=   0.0s\n",
      "[CV 3/5] END ...............C=0.1, kernel=poly;, score=-2.682 total time=   0.0s\n",
      "[CV 4/5] END ...............C=0.1, kernel=poly;, score=-2.975 total time=   0.0s\n",
      "[CV 5/5] END ...............C=0.1, kernel=poly;, score=-2.405 total time=   0.0s\n",
      "[CV 1/5] END ...............C=1, kernel=linear;, score=-2.320 total time=   0.0s\n",
      "[CV 2/5] END ...............C=1, kernel=linear;, score=-2.253 total time=   0.0s\n",
      "[CV 3/5] END ...............C=1, kernel=linear;, score=-2.682 total time=   0.0s\n",
      "[CV 4/5] END ...............C=1, kernel=linear;, score=-2.900 total time=   0.0s\n",
      "[CV 5/5] END ...............C=1, kernel=linear;, score=-2.405 total time=   0.0s\n",
      "[CV 1/5] END ..................C=1, kernel=rbf;, score=-2.320 total time=   0.0s\n",
      "[CV 2/5] END ..................C=1, kernel=rbf;, score=-2.253 total time=   0.0s\n",
      "[CV 3/5] END ..................C=1, kernel=rbf;, score=-2.682 total time=   0.0s\n",
      "[CV 4/5] END ..................C=1, kernel=rbf;, score=-2.975 total time=   0.0s\n",
      "[CV 5/5] END ..................C=1, kernel=rbf;, score=-2.405 total time=   0.0s\n",
      "[CV 1/5] END .................C=1, kernel=poly;, score=-2.320 total time=   0.0s\n",
      "[CV 2/5] END .................C=1, kernel=poly;, score=-2.253 total time=   0.0s\n",
      "[CV 3/5] END .................C=1, kernel=poly;, score=-2.682 total time=   0.0s\n",
      "[CV 4/5] END .................C=1, kernel=poly;, score=-2.975 total time=   0.0s\n",
      "[CV 5/5] END .................C=1, kernel=poly;, score=-2.405 total time=   0.0s\n",
      "[CV 1/5] END ..............C=10, kernel=linear;, score=-2.320 total time=   0.0s\n",
      "[CV 2/5] END ..............C=10, kernel=linear;, score=-2.253 total time=   0.0s\n",
      "[CV 3/5] END ..............C=10, kernel=linear;, score=-2.682 total time=   0.0s\n",
      "[CV 4/5] END ..............C=10, kernel=linear;, score=-2.975 total time=   0.0s\n",
      "[CV 5/5] END ..............C=10, kernel=linear;, score=-2.405 total time=   0.0s\n",
      "[CV 1/5] END .................C=10, kernel=rbf;, score=-2.320 total time=   0.0s\n",
      "[CV 2/5] END .................C=10, kernel=rbf;, score=-2.253 total time=   0.0s\n",
      "[CV 3/5] END .................C=10, kernel=rbf;, score=-2.682 total time=   0.0s\n",
      "[CV 4/5] END .................C=10, kernel=rbf;, score=-2.975 total time=   0.0s\n",
      "[CV 5/5] END .................C=10, kernel=rbf;, score=-2.405 total time=   0.0s\n",
      "[CV 1/5] END ................C=10, kernel=poly;, score=-2.320 total time=   0.0s\n",
      "[CV 2/5] END ................C=10, kernel=poly;, score=-2.253 total time=   0.0s\n",
      "[CV 3/5] END ................C=10, kernel=poly;, score=-2.682 total time=   0.0s\n",
      "[CV 4/5] END ................C=10, kernel=poly;, score=-2.975 total time=   0.0s\n",
      "[CV 5/5] END ................C=10, kernel=poly;, score=-2.405 total time=   0.0s\n"
     ]
    }
   ],
   "source": [
    "SVM_updrs4=pred(X_train_UPDRS4, y_train.updrs_4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "1de9ba31",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'UPDRS_1': -5.616390169380195, 'UPDRS_2': -5.742620682542703, 'UPDRS_3': -12.568384735827516, 'UPDRS_4': -2.511805232218421}\n"
     ]
    }
   ],
   "source": [
    "RMSE_SVM={\"UPDRS_1\":SVM_updrs1[1],\"UPDRS_2\":SVM_updrs2[1],\"UPDRS_3\":SVM_updrs3[1],\"UPDRS_4\":SVM_updrs4[1]}\n",
    "print(RMSE_SVM)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c4a1ab9",
   "metadata": {},
   "source": [
    "Compare RMSE of light GBM with SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "216a5f81",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'UPDRS_1': -4.744981175550429, 'UPDRS_2': -4.573803939357066, 'UPDRS_3': -10.169609133540808, 'UPDRS_4': -2.0306641374085834}\n"
     ]
    }
   ],
   "source": [
    "print(RMSE_lightgbm)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "56fa0d76",
   "metadata": {},
   "source": [
    "The RMSE for light GBM is much smaller than SVM, which means it works better."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d4b7073",
   "metadata": {},
   "source": [
    "We will now look into logistic regression and see whether that could improve the RMSE. Logistic regression involves categorical response variables. We will consider each score to be high or low based on the median cut-off and use features to predict the categories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "7326ea45",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train[\"updrs1_category\"]=y_train[\"updrs_1\"].apply(lambda x: 0 if x>y_train.updrs_1.mean() else 1)\n",
    "y_train[\"updrs2_category\"]=y_train[\"updrs_2\"].apply(lambda x: 0 if x>y_train.updrs_2.mean() else 1)\n",
    "y_train[\"updrs3_category\"]=y_train[\"updrs_3\"].apply(lambda x: 0 if x>y_train.updrs_3.mean() else 1)\n",
    "y_train[\"updrs4_category\"]=y_train[\"updrs_4\"].apply(lambda x: 0 if x>y_train.updrs_4.mean() else 1)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0dd0ad66",
   "metadata": {},
   "source": [
    "We will now use grid search using C which is strength of regularization "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "249ce580",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tuned hyperparameters :(best parameters)  {'C': 0.1}\n",
      "accuracy for UPDRS1 : 0.6919835841313269\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "grid={\"C\":np.logspace(-3,3,7)}\n",
    "logreg=LogisticRegression()\n",
    "logreg_cv=GridSearchCV(logreg,grid,cv=10)\n",
    "logreg_cv.fit(X_train_UPDRS1,y_train.updrs1_category)\n",
    "logreg_cv.best_params_\n",
    "print(\"tuned hyperparameters :(best parameters) \",logreg_cv.best_params_)\n",
    "print(\"accuracy for UPDRS1 :\",logreg_cv.best_score_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "f4dbe5ed",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tuned hyperparameters :(best parameters)  {'C': 0.1}\n",
      "accuracy for UPDRS1 : 0.7129958960328318\n"
     ]
    }
   ],
   "source": [
    "logreg_cv.fit(X_train_UPDRS2,y_train.updrs2_category)\n",
    "print(\"tuned hyperparameters :(best parameters) \",logreg_cv.best_params_)\n",
    "print(\"accuracy for UPDRS1 :\",logreg_cv.best_score_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "0ffe0f9e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tuned hyperparameters :(best parameters)  {'C': 10.0}\n",
      "accuracy for UPDRS1 : 0.7645554035567715\n"
     ]
    }
   ],
   "source": [
    "logreg_cv.fit(X_train_UPDRS3,y_train.updrs3_category)\n",
    "print(\"tuned hyperparameters :(best parameters) \",logreg_cv.best_params_)\n",
    "print(\"accuracy for UPDRS1 :\",logreg_cv.best_score_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "0fbfd578",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tuned hyperparameters :(best parameters)  {'C': 100.0}\n",
      "accuracy for UPDRS1 : 0.8044733242134063\n"
     ]
    }
   ],
   "source": [
    "logreg_cv.fit(X_train_UPDRS4,y_train.updrs4_category)\n",
    "print(\"tuned hyperparameters :(best parameters) \",logreg_cv.best_params_)\n",
    "print(\"accuracy for UPDRS1 :\",logreg_cv.best_score_)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "72cbe930",
   "metadata": {},
   "source": [
    "**When we look at accuracy based on using categories rather than scores, the accuracy is better than a random 50%. For UPDRS2, UPDRS3 and UPDRS4 scores, the accuracy is above 70%. While for UPDRS1  it is 69%. Predicting categories rather than scores is simpler and our features for each score category do better. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea971f9e",
   "metadata": {},
   "source": [
    "Let us use the logistic regression model to predict categories for UPDRS scores in our test dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c7cfef5",
   "metadata": {},
   "source": [
    "First we will convert test dataset categories "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "f9989560",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test[\"updrs1_category\"]=y_test[\"updrs_1\"].apply(lambda x: 0 if x>y_test.updrs_1.mean() else 1)\n",
    "y_test[\"updrs2_category\"]=y_test[\"updrs_2\"].apply(lambda x: 0 if x>y_test.updrs_2.mean() else 1)\n",
    "y_test[\"updrs3_category\"]=y_test[\"updrs_3\"].apply(lambda x: 0 if x>y_test.updrs_3.mean() else 1)\n",
    "y_test[\"updrs4_category\"]=y_test[\"updrs_4\"].apply(lambda x: 0 if x>y_test.updrs_4.mean() else 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b141f38",
   "metadata": {},
   "source": [
    "Now we will use selected features for the test dataset for predicting each of the categories. We will also use the regularisation parameters selected for each of the UPDRS scores. We will evaluate the testing dataset by looking at accuracy and F1 scores."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "6f950a24",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Accuracy of UPDRS1: 0.76\n",
      "Test F1 score of UPDRS1: 0.78\n"
     ]
    }
   ],
   "source": [
    "logreg=LogisticRegression(C=0.1)\n",
    "logreg.fit(X_train_UPDRS1,y_train.updrs1_category)\n",
    "X_test_UPDRS1=X_test[features_UPDRS1.loc[:,0].tolist()]\n",
    "y_pred_updrs1 = logreg.predict(X_test_UPDRS1)\n",
    "\n",
    "# Evaluate model performance on the test data\n",
    "accuracy_updrs1 = accuracy_score(y_test.updrs1_category, y_pred_updrs1)\n",
    "print(f'Test Accuracy of UPDRS1: {accuracy_updrs1:.2f}')\n",
    "\n",
    "F1_score_updrs1= f1_score(y_test.updrs1_category, y_pred_updrs1)\n",
    "print(f'Test F1 score of UPDRS1: {F1_score_updrs1:.2f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "243aed43",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Accuracy of UPDRS2: 0.72\n",
      "Test F1 score of UPDRS2: 0.77\n"
     ]
    }
   ],
   "source": [
    "logreg=LogisticRegression(C=0.1)\n",
    "logreg.fit(X_train_UPDRS2,y_train.updrs2_category)\n",
    "X_test_UPDRS2=X_test[features_UPDRS2.loc[:,0].tolist()]\n",
    "y_pred_updrs2 = logreg.predict(X_test_UPDRS2)\n",
    "\n",
    "# Evaluate model performance on the test data\n",
    "accuracy_updrs2 = accuracy_score(y_test.updrs2_category, y_pred_updrs2)\n",
    "print(f'Test Accuracy of UPDRS2: {accuracy_updrs2:.2f}')\n",
    "\n",
    "F1_score_updrs2= f1_score(y_test.updrs2_category,  y_pred_updrs2)\n",
    "print(f'Test F1 score of UPDRS2: {F1_score_updrs2:.2f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "256c8ea5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Accuracy of UPDRS3: 0.74\n",
      "Test F1 score of UPDRS3: 0.73\n"
     ]
    }
   ],
   "source": [
    "logreg=LogisticRegression(C=10)\n",
    "logreg.fit(X_train_UPDRS3,y_train.updrs3_category)\n",
    "X_test_UPDRS3=X_test[features_UPDRS3.loc[:,0].tolist()]\n",
    "y_pred_updrs3 = logreg.predict(X_test_UPDRS3)\n",
    "\n",
    "\n",
    "accuracy_updrs3 = accuracy_score(y_test.updrs3_category, y_pred_updrs3)\n",
    "print(f'Test Accuracy of UPDRS3: {accuracy_updrs3:.2f}')\n",
    "\n",
    "F1_score_updrs3= f1_score(y_test.updrs3_category,  y_pred_updrs3)\n",
    "print(f'Test F1 score of UPDRS3: {F1_score_updrs3:.2f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "7e2c813a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Accuracy of UPDRS4: 0.73\n",
      "Test F1 score of UPDRS4: 0.80\n"
     ]
    }
   ],
   "source": [
    "logreg=LogisticRegression(C=100)\n",
    "logreg.fit(X_train_UPDRS4,y_train.updrs3_category)\n",
    "X_test_UPDRS4=X_test[features_UPDRS4.loc[:,0].tolist()]\n",
    "y_pred_updrs4 = logreg.predict(X_test_UPDRS4)\n",
    "\n",
    "# Evaluate model performance on the test data\n",
    "accuracy_updrs4 = accuracy_score(y_test.updrs4_category, y_pred_updrs4)\n",
    "print(f'Test Accuracy of UPDRS4: {accuracy_updrs4 :.2f}')\n",
    "\n",
    "F1_score_updrs4= f1_score(y_test.updrs4_category,  y_pred_updrs4)\n",
    "print(f'Test F1 score of UPDRS4: {F1_score_updrs4:.2f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30a6e621",
   "metadata": {},
   "source": [
    "tabulate the results below with F1 scores and Accuracy scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "45491c38",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+-----------------+-----------------+\n",
      "| UPDRS   |   Test_Accuracy |   Test_F1_score |\n",
      "+=========+=================+=================+\n",
      "| UPDRS1  |            0.76 |            0.78 |\n",
      "+---------+-----------------+-----------------+\n",
      "| UPDRS2  |            0.72 |            0.77 |\n",
      "+---------+-----------------+-----------------+\n",
      "| UPDRS3  |            0.74 |            0.73 |\n",
      "+---------+-----------------+-----------------+\n",
      "| UPDRS4  |            0.73 |            0.8  |\n",
      "+---------+-----------------+-----------------+\n"
     ]
    }
   ],
   "source": [
    "Scores = [\n",
    "    [\"UPDRS1\", round(accuracy_updrs1 ,2),round(F1_score_updrs1, 2)], \n",
    "    [\"UPDRS2\", round(accuracy_updrs2 ,2),round(F1_score_updrs2, 2)], \n",
    "    [\"UPDRS3\", round(accuracy_updrs3, 2),round(F1_score_updrs3, 2)], \n",
    "      [\"UPDRS4\",round(accuracy_updrs4, 2),round(F1_score_updrs4, 2)]\n",
    "]\n",
    " \n",
    "# create header\n",
    "head = [\"UPDRS\", \"Test_Accuracy\",\"Test_F1_score\"]\n",
    " \n",
    "# display table\n",
    "print(tabulate(Scores, headers=head, tablefmt=\"grid\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0057d35",
   "metadata": {},
   "source": [
    "### **The test value accuracy and F1 scores show that the models perform well when used to predict UPDRS score categories. However, our models which were used to predict the UPDRS scores had poor RMSE values, this indicates that either training dataset was too small or despite using other features along with protein and peptide abundance were insufficient for predicting UPDRS scores "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
